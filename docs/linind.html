<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 9 Linear Independence |  Linear Algebra for Data Science   with examples in R and Python</title>
  <meta name="description" content="Linear Algebra for Data Science with examples in R." />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 9 Linear Independence |  Linear Algebra for Data Science   with examples in R and Python" />
  <meta property="og:type" content="book" />
  
  <meta property="og:image" content="MSALogo.png" />
  <meta property="og:description" content="Linear Algebra for Data Science with examples in R." />
  <meta name="github-repo" content="rstudio/linalg-master" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 9 Linear Independence |  Linear Algebra for Data Science   with examples in R and Python" />
  
  <meta name="twitter:description" content="Linear Algebra for Data Science with examples in R." />
  <meta name="twitter:image" content="MSALogo.png" />

<meta name="author" content="Shaina Race Bennett, PhD" />


<meta name="date" content="2021-05-05" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="lsapp.html"/>
<link rel="next" href="pca.html"/>
<script src="libs/header-attrs-2.6/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/htmlwidgets-1.5.1/htmlwidgets.js"></script>
<script src="libs/plotly-binding-4.9.2.1/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/crosstalk-1.1.0.1/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk-1.1.0.1/js/crosstalk.min.js"></script>
<link href="libs/plotly-htmlwidgets-css-1.52.2/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotly-main-1.52.2/plotly-latest.min.js"></script>
<script src="libs/d3-4.5.0/d3.min.js"></script>
<script src="libs/forceNetwork-binding-0.4/forceNetwork.js"></script>
<!DOCTYPE html>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  loader: {load: ['[tex]/cancel', '[tex]/systeme']},
  TeX: {
    packages: {'[+]': ['cancel','systeme','boldsymbol']}
  }
});
</script>

<script type="text/javascript" id="MathJax-script"
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
</script>

<span class="math" style="display:none">
\(\usepackage{amsfonts}
\usepackage{cancel}
\usepackage{amsmath}
\usepackage{systeme}
\usepackage{amsthm}
\usepackage{xcolor}
\usepackage{boldsymbol}
\newenvironment{am}[1]{%
  \left(\begin{array}{@{}*{#1}{c}|c@{}}
}{%
  \end{array}\right)
}
\newcommand{\bordermatrix}[3]{\begin{matrix} ~ & \begin{matrix} #1 \end{matrix} \\ \begin{matrix} #2 \end{matrix}\hspace{-1em} & #3 \end{matrix}}
\newcommand{\eref}[1]{Example~\ref{#1}}
\newcommand{\fref}[1]{Figure~\ref{#1}}
\newcommand{\tref}[1]{Table~\ref{#1}}
\newcommand{\sref}[1]{Section~\ref{#1}}
\newcommand{\cref}[1]{Chapter~\ref{#1}}
\newtheorem{definition}{Definition}
\newtheorem{lemma}{Lemma}
\newtheorem{fact}{Fact}
\newtheorem{thm}{Theorem}
\newtheorem{example}{Example}[section]
\newcommand{\To}{\Rightarrow}
\newcommand{\del}{\nabla}
\renewcommand{\Re}{\mathbb{R}}
\renewcommand{\O}{\mathcal{O}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\ben}{\begin{enumerate}}
\newcommand{\een}{\end{enumerate}}
\newcommand{\eps}{\epsilon}
\newcommand{\cont}{\Rightarrow \Leftarrow}
\newcommand{\back}{\backslash}
\newcommand{\norm}[1]{\|{#1}\|}
\newcommand{\abs}[1]{|{#1}|}
\newcommand{\ip}[1]{\langle{#1}\rangle}
\newcommand{\bo}{\mathbf}
\newcommand{\mean}{\boldsymbol\mu}
\newcommand{\cov}{\boldsymbol\Sigma}
\newcommand{\wt}{\widetilde}
\newcommand{\p}{\textbf{p}}
\newcommand{\ff}{\textbf{f}}
\newcommand{\aj}{\textbf{a}_j}
\newcommand{\ajhat}{\widehat{\textbf{a}_j}}
\newcommand{\I}{\textbf{I}}
\newcommand{\A}{\textbf{A}}
\newcommand{\B}{\textbf{B}}
\newcommand{\bL}{\textbf{L}}
\newcommand{\bP}{\textbf{P}}
\newcommand{\bD}{\textbf{D}}
\newcommand{\bS}{\textbf{S}}
\newcommand{\bW}{\textbf{W}}
\newcommand{\id}{\textbf{I}}
\newcommand{\M}{\textbf{M}}
\renewcommand{\B}{\textbf{B}}
\newcommand{\V}{\textbf{V}}
\newcommand{\U}{\textbf{U}}
\newcommand{\y}{\textbf{y}}
\newcommand{\bv}{\textbf{v}}
\renewcommand{\v}{\textbf{v}}
\newcommand{\cC}{\mathscr{C}}
\newcommand{\e}{\textbf{e}}
\newcommand{\w}{\textbf{w}}
\newcommand{\h}{\textbf{h}}
\renewcommand{\b}{\textbf{b}}
\renewcommand{\a}{\textbf{a}}
\renewcommand{\u}{\textbf{u}}
\newcommand{\C}{\textbf{C}}
\newcommand{\D}{\textbf{D}}
\newcommand{\cc}{\textbf{c}}
\newcommand{\Q}{\textbf{Q}}
\renewcommand{\S}{\textbf{S}}
\newcommand{\X}{\textbf{X}}
\newcommand{\Z}{\textbf{Z}}
\newcommand{\z}{\textbf{z}}
\newcommand{\Y}{\textbf{Y}}
\newcommand{\plane}{\textit{P}}
\newcommand{\mxn}{$m\mbox{x}n$}
\newcommand{\kmeans}{\textit{k}-means\,}
\newcommand{\bbeta}{\boldsymbol\beta}
\newcommand{\ssigma}{\boldsymbol\Sigma}
\newcommand{\xrow}[1]{\mathbf{X}_{{#1}\star}}
\newcommand{\xcol}[1]{\mathbf{X}_{\star{#1}}}
\newcommand{\yrow}[1]{\mathbf{Y}_{{#1}\star}}
\newcommand{\ycol}[1]{\mathbf{Y}_{\star{#1}}}
\newcommand{\crow}[1]{\mathbf{C}_{{#1}\star}}
\newcommand{\ccol}[1]{\mathbf{C}_{\star{#1}}}
\newcommand{\red}[1]{\textcolor{red}{#1}}
\newcommand{\blue}[1]{\textcolor{blue}{#1}}
\newcommand{\arow}[1]{\mathbf{A}_{{#1}\star}}
\newcommand{\acol}[1]{\mathbf{A}_{\star{#1}}}
\newcommand{\brow}[1]{\mathbf{B}_{{#1}\star}}
\newcommand{\bcol}[1]{\mathbf{B}_{\star{#1}}}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}
\renewcommand{\t}{ \indent}
\newcommand{\nt}{ \indent}
\newcommand{\x}{\mathbf{x}}
\renewcommand{\Y}{\mathbf{Y}}
\newcommand{\ep}{\mathbf{\epsilon}}
\renewcommand{\pm}{\left(\begin{matrix}}
\renewcommand{\mp}{\end{matrix}\right)}
\newcommand{\bm}{\bordermatrix}
\usepackage{pdfpages,cancel}
\newenvironment{code}{\Verbatim [formatcom=\color{blue}]}{\endVerbatim}
\)
</span>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><center><img src="figs/iaaicon.png" width="50"></center></li>
<li><center><strong> Linear Algebra for Data Science </strong></center></li>
<li><center><strong> with examples in R and Python </strong></center></li>

<li class="divider"></li>
<li><a href="index.html#section"></a></li>
<li class="chapter" data-level="1" data-path="preface.html"><a href="preface.html"><i class="fa fa-check"></i><b>1</b> Preface</a>
<ul>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#structure-of-the-book"><i class="fa fa-check"></i>Structure of the book</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#about-the-author"><i class="fa fa-check"></i>About the author</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#acknowledgements"><i class="fa fa-check"></i>Acknowledgements</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>2</b> Introduction</a>
<ul>
<li class="chapter" data-level="2.1" data-path="intro.html"><a href="intro.html#what-is-linear-algebra"><i class="fa fa-check"></i><b>2.1</b> What is Linear Algebra?</a></li>
<li class="chapter" data-level="2.2" data-path="intro.html"><a href="intro.html#why-linear-algebra"><i class="fa fa-check"></i><b>2.2</b> Why Linear Algebra</a></li>
<li class="chapter" data-level="2.3" data-path="intro.html"><a href="intro.html#describing-matrices-and-vectors"><i class="fa fa-check"></i><b>2.3</b> Describing Matrices and Vectors</a></li>
<li class="chapter" data-level="2.4" data-path="intro.html"><a href="intro.html#vectors"><i class="fa fa-check"></i><b>2.4</b> Vectors</a></li>
<li class="chapter" data-level="2.5" data-path="intro.html"><a href="intro.html#matrix-operations"><i class="fa fa-check"></i><b>2.5</b> Matrix Operations</a></li>
<li class="chapter" data-level="2.6" data-path="intro.html"><a href="intro.html#special"><i class="fa fa-check"></i><b>2.6</b> Special Matrices and Vectors</a></li>
<li class="chapter" data-level="2.7" data-path="intro.html"><a href="intro.html#summary-of-conventional-notation"><i class="fa fa-check"></i><b>2.7</b> Summary of Conventional Notation</a></li>
<li class="chapter" data-level="2.8" data-path="intro.html"><a href="intro.html#exercises"><i class="fa fa-check"></i><b>2.8</b> Exercises</a></li>
<li class="chapter" data-level="2.9" data-path="intro.html"><a href="intro.html#list-of-key-terms"><i class="fa fa-check"></i><b>2.9</b> List of Key Terms</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="mult.html"><a href="mult.html"><i class="fa fa-check"></i><b>3</b> Matrix Arithmetic</a>
<ul>
<li class="chapter" data-level="3.1" data-path="mult.html"><a href="mult.html#matrix-addition-subtraction-and-scalar-multiplication"><i class="fa fa-check"></i><b>3.1</b> Matrix Addition, Subtraction, and Scalar Multiplication</a></li>
<li class="chapter" data-level="3.2" data-path="mult.html"><a href="mult.html#sec:vectoradd"><i class="fa fa-check"></i><b>3.2</b> Geometry of Vector Addition and Scalar Multiplication</a></li>
<li class="chapter" data-level="3.3" data-path="mult.html"><a href="mult.html#linear-combinations"><i class="fa fa-check"></i><b>3.3</b> Linear Combinations</a></li>
<li class="chapter" data-level="3.4" data-path="mult.html"><a href="mult.html#matrix-multiplication"><i class="fa fa-check"></i><b>3.4</b> Matrix Multiplication</a></li>
<li class="chapter" data-level="3.5" data-path="mult.html"><a href="mult.html#vector-outer-products"><i class="fa fa-check"></i><b>3.5</b> Vector Outer Products</a></li>
<li class="chapter" data-level="3.6" data-path="mult.html"><a href="mult.html#the-identity-and-the-matrix-inverse"><i class="fa fa-check"></i><b>3.6</b> The Identity and the Matrix Inverse</a></li>
<li class="chapter" data-level="3.7" data-path="mult.html"><a href="mult.html#exercises-1"><i class="fa fa-check"></i><b>3.7</b> Exercises</a></li>
<li class="chapter" data-level="" data-path="mult.html"><a href="mult.html#list-of-key-terms-1"><i class="fa fa-check"></i>List of Key Terms</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="multapp.html"><a href="multapp.html"><i class="fa fa-check"></i><b>4</b> Applications of Matrix Multiplication</a>
<ul>
<li class="chapter" data-level="4.1" data-path="multapp.html"><a href="multapp.html#systems-of-equations"><i class="fa fa-check"></i><b>4.1</b> Systems of Equations</a></li>
<li class="chapter" data-level="4.2" data-path="multapp.html"><a href="multapp.html#regression-analysis"><i class="fa fa-check"></i><b>4.2</b> Regression Analysis</a></li>
<li class="chapter" data-level="4.3" data-path="multapp.html"><a href="multapp.html#linear-combinations-1"><i class="fa fa-check"></i><b>4.3</b> Linear Combinations</a></li>
<li class="chapter" data-level="4.4" data-path="multapp.html"><a href="multapp.html#multapp-ex"><i class="fa fa-check"></i><b>4.4</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="r-programming-basics.html"><a href="r-programming-basics.html"><i class="fa fa-check"></i><b>5</b> R Programming Basics</a></li>
<li class="chapter" data-level="6" data-path="solvesys.html"><a href="solvesys.html"><i class="fa fa-check"></i><b>6</b> Solving Systems of Equations</a>
<ul>
<li class="chapter" data-level="6.1" data-path="solvesys.html"><a href="solvesys.html#gaussian-elimination"><i class="fa fa-check"></i><b>6.1</b> Gaussian Elimination</a></li>
<li class="chapter" data-level="6.2" data-path="solvesys.html"><a href="solvesys.html#three-types-of-systems"><i class="fa fa-check"></i><b>6.2</b> Three Types of Systems</a></li>
<li class="chapter" data-level="6.3" data-path="solvesys.html"><a href="solvesys.html#solving-matrix-equations"><i class="fa fa-check"></i><b>6.3</b> Solving Matrix Equations</a></li>
<li class="chapter" data-level="6.4" data-path="solvesys.html"><a href="solvesys.html#exercises-2"><i class="fa fa-check"></i><b>6.4</b> Exercises</a></li>
<li class="chapter" data-level="6.5" data-path="solvesys.html"><a href="solvesys.html#list-of-key-terms-2"><i class="fa fa-check"></i><b>6.5</b> List of Key Terms</a></li>
<li class="chapter" data-level="6.6" data-path="solvesys.html"><a href="solvesys.html#gauss-jordan-elimination-in-r"><i class="fa fa-check"></i><b>6.6</b> Gauss-Jordan Elimination in R</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="leastsquares.html"><a href="leastsquares.html"><i class="fa fa-check"></i><b>7</b> Least Squares</a></li>
<li class="chapter" data-level="8" data-path="lsapp.html"><a href="lsapp.html"><i class="fa fa-check"></i><b>8</b> Applications of Least Squares</a>
<ul>
<li class="chapter" data-level="8.1" data-path="lsapp.html"><a href="lsapp.html#simple-linear-regression"><i class="fa fa-check"></i><b>8.1</b> Simple Linear Regression</a></li>
<li class="chapter" data-level="8.2" data-path="lsapp.html"><a href="lsapp.html#multiple-linear-regression"><i class="fa fa-check"></i><b>8.2</b> Multiple Linear Regression</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="linind.html"><a href="linind.html"><i class="fa fa-check"></i><b>9</b> Linear Independence</a>
<ul>
<li class="chapter" data-level="9.1" data-path="linind.html"><a href="linind.html#linear-independence"><i class="fa fa-check"></i><b>9.1</b> Linear Independence</a></li>
<li class="chapter" data-level="9.2" data-path="linind.html"><a href="linind.html#span"><i class="fa fa-check"></i><b>9.2</b> Span of Vectors</a></li>
<li class="chapter" data-level="9.3" data-path="linind.html"><a href="linind.html#exercises-3"><i class="fa fa-check"></i><b>9.3</b> Exercises</a></li>
<li class="chapter" data-level="" data-path="linind.html"><a href="linind.html#list-of-key-terms-3"><i class="fa fa-check"></i>List of Key Terms</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="pca.html"><a href="pca.html"><i class="fa fa-check"></i><b>10</b> Principal Components Analysis</a>
<ul>
<li class="chapter" data-level="10.1" data-path="pca.html"><a href="pca.html#geometrical-comparison-with-least-squares"><i class="fa fa-check"></i><b>10.1</b> Geometrical comparison with Least Squares</a></li>
<li class="chapter" data-level="10.2" data-path="pca.html"><a href="pca.html#covariance-or-correlation-matrix"><i class="fa fa-check"></i><b>10.2</b> Covariance or Correlation Matrix?</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="pca-in-r.html"><a href="pca-in-r.html"><i class="fa fa-check"></i><b>11</b> PCA in R</a>
<ul>
<li class="chapter" data-level="11.1" data-path="pca-in-r.html"><a href="pca-in-r.html#variable-clustering-with-pca"><i class="fa fa-check"></i><b>11.1</b> Variable Clustering with PCA</a></li>
<li class="chapter" data-level="11.2" data-path="pca-in-r.html"><a href="pca-in-r.html#pca-as-svd"><i class="fa fa-check"></i><b>11.2</b> PCA as SVD</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="pcaapp.html"><a href="pcaapp.html"><i class="fa fa-check"></i><b>12</b> Applications of Principal Components</a>
<ul>
<li class="chapter" data-level="12.1" data-path="pcaapp.html"><a href="pcaapp.html#dimension-reduction"><i class="fa fa-check"></i><b>12.1</b> Dimension reduction</a></li>
<li class="chapter" data-level="12.2" data-path="pcaapp.html"><a href="pcaapp.html#exploratory-analysis"><i class="fa fa-check"></i><b>12.2</b> Exploratory Analysis</a></li>
<li class="chapter" data-level="12.3" data-path="pcaapp.html"><a href="pcaapp.html#fifa-soccer-players"><i class="fa fa-check"></i><b>12.3</b> FIFA Soccer Players</a></li>
<li class="chapter" data-level="12.4" data-path="pcaapp.html"><a href="pcaapp.html#cancer-genetics"><i class="fa fa-check"></i><b>12.4</b> Cancer Genetics</a></li>
<li class="chapter" data-level="12.5" data-path="pcaapp.html"><a href="pcaapp.html#rappasvd"><i class="fa fa-check"></i><b>12.5</b> Image Compression</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="fa.html"><a href="fa.html"><i class="fa fa-check"></i><b>13</b> Factor Analysis</a>
<ul>
<li class="chapter" data-level="13.1" data-path="fa.html"><a href="fa.html#assumptions-of-factor-analysis"><i class="fa fa-check"></i><b>13.1</b> Assumptions of Factor Analysis</a></li>
<li class="chapter" data-level="13.2" data-path="fa.html"><a href="fa.html#determining-factorability"><i class="fa fa-check"></i><b>13.2</b> Determining Factorability</a></li>
<li class="chapter" data-level="13.3" data-path="fa.html"><a href="fa.html#communalities"><i class="fa fa-check"></i><b>13.3</b> Communalities</a></li>
<li class="chapter" data-level="13.4" data-path="fa.html"><a href="fa.html#number-of-factors"><i class="fa fa-check"></i><b>13.4</b> Number of Factors</a></li>
<li class="chapter" data-level="13.5" data-path="fa.html"><a href="fa.html#rotation-of-factors"><i class="fa fa-check"></i><b>13.5</b> Rotation of Factors</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="factor-analysis.html"><a href="factor-analysis.html"><i class="fa fa-check"></i><b>14</b> Factor Analysis</a>
<ul>
<li class="chapter" data-level="14.1" data-path="factor-analysis.html"><a href="factor-analysis.html#pca-rotations"><i class="fa fa-check"></i><b>14.1</b> PCA Rotations</a></li>
<li class="chapter" data-level="14.2" data-path="factor-analysis.html"><a href="factor-analysis.html#ex-personality-tests"><i class="fa fa-check"></i><b>14.2</b> Ex: Personality Tests</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="dimension-reduction-for-visualization.html"><a href="dimension-reduction-for-visualization.html"><i class="fa fa-check"></i><b>15</b> Dimension Reduction for Visualization</a>
<ul>
<li class="chapter" data-level="15.1" data-path="dimension-reduction-for-visualization.html"><a href="dimension-reduction-for-visualization.html#multidimensional-scaling"><i class="fa fa-check"></i><b>15.1</b> Multidimensional Scaling</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="social-network-analysis.html"><a href="social-network-analysis.html"><i class="fa fa-check"></i><b>16</b> Social Network Analysis</a>
<ul>
<li class="chapter" data-level="16.1" data-path="social-network-analysis.html"><a href="social-network-analysis.html#working-with-network-data"><i class="fa fa-check"></i><b>16.1</b> Working with Network Data</a></li>
<li class="chapter" data-level="16.2" data-path="social-network-analysis.html"><a href="social-network-analysis.html#network-visualization---igraph-package"><i class="fa fa-check"></i><b>16.2</b> Network Visualization - <code>igraph</code> package</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./"><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAP///wAAACH5BAEAAAAALAAAAAABAAEAAAICRAEAOw==" width="2" height="200" />
Linear Algebra for Data Science <br>
with examples in R and Python</p></a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="linind" class="section level1" number="9">
<h1><span class="header-section-number">Chapter 9</span> Linear Independence</h1>
<p>One of the most central ideas in all of Linear Algebra is that of <strong>linear independence</strong>. For regression problems, it is repeatedly stressed that <em>multicollinearity</em> is problematic. Multicollinearity is simply a statistical term for linear dependence. It’s bad. Having a firm understanding of linear combinations, we can develop the important concept of linear independence.</p>
<div id="linear-independence" class="section level2" number="9.1">
<h2><span class="header-section-number">9.1</span> Linear Independence</h2>
<div class="Smain">
<div class="Scontainer">
<div class="Stext-header">
Definition @ref().1: Linear Dependence and Linear Independence
</div>
<div class="Stext">
<p>A set of vectors <span class="math inline">\(\{\v_1,\v_2,\dots, \v_n\}\)</span> is <strong>linearly dependent</strong> if we can express the zero vector, <span class="math inline">\(\bo{0}\)</span>, as non-trivial linear combination of the vectors. In other words there exist some constants <span class="math inline">\(\alpha_1,\alpha_2,\dots \alpha_n\)</span> (non-trivial means that these constants are not <em>all</em> zero) for which
<span class="math display">\[\begin{equation}
\alpha_1\v_1 +\alpha_2\v_2 + \dots +\alpha_n\v_n=\bo{0}.
\label{triv}
\end{equation}\]</span></p>
A set of terms is <strong>linearly independent</strong> if Equation  has only the trivial solution (<span class="math inline">\(\alpha_1=\alpha_2=\dots=\alpha_n = 0\)</span>).
</div>
</div>
</div>
<p>Another way to express linear dependence is to say that we can write one of the vectors as a linear combination of the others. If there exists a non-trivial set of coefficients <span class="math inline">\(\alpha_1,\alpha_2, \dots, \alpha_n\)</span> for which
<span class="math display">\[\alpha_1\v_1 +\alpha_2\v_2 + \dots +\alpha_n\v_n=\bo{0}\]</span>
then for <span class="math inline">\(\alpha_j \neq 0\)</span> we could write
<span class="math display">\[\v_j=-\frac{1}{\alpha_j} \sum_{\substack{i=1\\i \neq j}}^n \alpha_i \v_i\]</span></p>
<div class="S2main">
<div class="S2container">
<div class="S2text-header">
Example @ref().1: Linearly Dependent Vectors
</div>
<div class="S2text">
The vectors <span class="math inline">\(\v_1 =\pm 1\\2\\2 \mp, \v_2 = \pm 1\\2\\3 \mp, \mbox{ and } \v_3 = \pm 3\\6\\7 \mp\)</span> are linearly dependent because
<span class="math display">\[\v_3 = 2\v_1+\v_2\]</span>
or, equivalently, because
<span class="math display">\[2\v_1+\v_2-\v_3 = \bo{0}\]</span>
</div>
</div>
</div>
<div id="determining-linear-independence" class="section level3" number="9.1.1">
<h3><span class="header-section-number">9.1.1</span> Determining Linear Independence</h3>
<p>You should realize that the linear combination expressed Definition  can be written as a matrix vector product. Let <span class="math inline">\(\A_{m\times n} = (\A_1|\A_2|\dots|\A_n)\)</span> be a matrix. Then by Definition , the columns of <span class="math inline">\(\A\)</span> are linearly independent if and only if the equation
<span class="math display">\[\begin{equation}
\label{eq:homo}
\A\x = \bo{0}
\end{equation}\]</span>
has only the trivial solution, <span class="math inline">\(\x=0\)</span>. Equation  is commonly known as the homogeneous linear equation. For this equation to have only the trivial solution, it must be the case that under Gauss-Jordan elimination, the augmented matrix <span class="math inline">\((\A|\bo{0})\)</span> reduces to <span class="math inline">\((\bo{I}|0)\)</span>. We have already seen this condition in our discussion about matrix inverses - if a square matrix <span class="math inline">\(\A\)</span> reduces to the identity matrix under Gauss-Jordan elimination then it is equivalently called <em>full rank, nonsingular, or invertible</em>. Now we add an additional condition equivalent to the others - the matrix <span class="math inline">\(\A\)</span> has linearly independent columns (<em>and rows</em>).</p>
<p>In Theorem  a important list of equivalent conditions regarding linear independence and invertibility is given.</p>
<div class="Smain">
<div class="Scontainer">
<div class="Stext-header">
Theorem @ref().2: Equivalent Conditions for Matrix Invertibility
</div>
<div class="Stext">
<p>Let <span class="math inline">\(\A\)</span> be an <span class="math inline">\(n\times n\)</span> matrix - a <em>square</em> matrix. Then the following statements are <em>equivalent</em>. (If one these statements is true, then all of these statements are true)</p>
<ul>
<li><span class="math inline">\(\A\)</span> is invertible (<span class="math inline">\(\A^{-1} exists\)</span>)</li>
<li><span class="math inline">\(\A\)</span> has full rank (<span class="math inline">\(rank(\A)=n\)</span>)</li>
<li>The columns of <span class="math inline">\(\A\)</span> are linearly independent</li>
<li>The rows of <span class="math inline">\(\A\)</span> are linearly independent</li>
<li>The system <span class="math inline">\(\A\x=\b\)</span>, <span class="math inline">\(\b\neq \bo{0}\)</span> has a unique solution</li>
<li><span class="math inline">\(\A\x=\bo{0} \Longrightarrow \x=\bo{0}\)</span></li>
<li><span class="math inline">\(\A\)</span> is nonsingular</li>
<li><span class="math inline">\(\A \xrightarrow{Gauss-Jordan} \bo{I}\)</span>
</div></li>
</ul>
</div>
</div>
</div>
</div>
<div id="span" class="section level2" number="9.2">
<h2><span class="header-section-number">9.2</span> Span of Vectors</h2>
<div class="Smain">
<div class="Scontainer">
<div class="Stext-header">
Definition @ref().3: Vector Span
</div>
<div class="Stext">
<p>The <strong>span</strong> of a single vector <span class="math inline">\(\v\)</span> is the set of all scalar multiples of <span class="math inline">\(\v\)</span>:
<span class="math display">\[span(\v)=\{\alpha\v\ \mbox{  for any constant  } \alpha\}\]</span>
The <strong>span</strong> of a collection of vectors, <span class="math inline">\(\V=\{\v_1,\v_2,\dots,\v_n\}\)</span> is the set of all linear combinations of these vectors:
<span class="math display">\[span(\V)=\{\alpha_1\v_1+\alpha_2\v_2+\dots+\alpha_n\v_n \mbox{ for any constants }\alpha_1,\dots,\alpha_n\}\]</span>
\end{mydef}

Recall that addition of vectors can be done geometrically using the <em>head-to-tail</em> method shown in .</p>
<figure>
<center>
<img src=figs/vectoradd.png width=300 />
<figcaption>
Geometrical addition of vectors: Head-to-tail
</figcaption>
</center>
</figure>
<p>If we have two linearly independent vectors on a coordinate plane, then any third vector can be written as a linear combination of them. This is because two vectors is sufficient to <em>span</em> the entire 2-dimensional plane. You should take a moment to convince yourself of this geometrically.</p>
In 3-space, two linearly independent vectors can still only span a plane.  depicts this situation. The set of all linearly combinations of the two vectors <span class="math inline">\(\a\)</span> and <span class="math inline">\(\b\)</span> (i.e. the <span class="math inline">\(span(\a,\b)\)</span>) carves out a plane. We call this a two-dimensional collection of vectors a <strong>subspace</strong> of <span class="math inline">\(\Re^3\)</span>. A subspace is formally defined in Definition .
<figure>
<center>
<img src=figs/span.png width=300 />
<figcaption>
The <span class="math inline">\(span(\a,\b)\)</span> in <span class="math inline">\(\Re^3\)</span> creates a plane (a 2-dimensional <em>subspace</em>)
</figcaption>
</center>
</figure>
</div>
</div>
</div>
<div class="Smain">
<div class="Scontainer">
<div class="Stext-header">
Definition @ref().4: Subspace
</div>
<div class="Stext">
<p>A <strong>subspace</strong>, <span class="math inline">\(\mathcal{S}\)</span> of <span class="math inline">\(\Re^n\)</span> is thought of as a ``flat’’ (having no curvature) surface within <span class="math inline">\(\Re^n\)</span>. It is a collection of vectors which satisfies the following conditions:</p>
<ol style="list-style-type: decimal">
<li>The origin (<span class="math inline">\(\bo{0}\)</span> vector) is contained in <span class="math inline">\(\mathcal{S}\)</span></li>
<li>If <span class="math inline">\(\x\)</span> and <span class="math inline">\(\y\)</span> are in <span class="math inline">\(\mathcal{S}\)</span> then the sum <span class="math inline">\(\x+\y\)</span> is also in <span class="math inline">\(\mathcal{S}\)</span></li>
<li>If <span class="math inline">\(\x\)</span> is in <span class="math inline">\(\mathcal{S}\)</span> and <span class="math inline">\(\alpha\)</span> is a constant then <span class="math inline">\(\alpha\x\)</span> is also in <span class="math inline">\(\mathcal{S}\)</span>
</div></li>
</ol>
</div>
</div>
<p>The span of two vectors <span class="math inline">\(\a\)</span> and <span class="math inline">\(\b\)</span> is a subspace because it satisfies these three conditions. (Can you prove it? See exercise 4).</p>
<div class="S2main">
<div class="S2container">
<div class="S2text-header">
Example @ref().1: Span
</div>
<div class="S2text">
<p>Let <span class="math inline">\(\a=\pm 1\\3\\4 \mp\)</span> and <span class="math inline">\(\b=\pm 3\\0\\1 \mp\)</span>. Explain why or why not each of the following vectors is contained in the <span class="math inline">\(span(\a,\b)\)</span>?</p>
<ol style="list-style-type: lower-alpha">
<li><span class="math inline">\(\x=\pm 5\\6\\9 \mp\)</span></li>
</ol>
<ul>
<li>To determine if <span class="math inline">\(\x\)</span> is in the <span class="math inline">\(span(\a,\b)\)</span> we need to find coefficients <span class="math inline">\(\alpha_1, \alpha_2\)</span> such that <span class="math display">\[\alpha_1\a+\alpha_2\b=\x.\]</span> Thus, we attempt to solve the system
<span class="math display">\[\pm 1&amp;3\\3&amp;0\\4&amp;1 \mp \pm \alpha_1\\ \alpha_2 \mp = \pm 5\\6\\9\mp.\]</span>
After Gaussian Elimination, we find that the system is consistent with the solution
<span class="math display">\[\pm\alpha_1\\ \alpha_2 \mp=\pm 2\\1\mp\]</span>
and so <span class="math inline">\(\x\)</span> is in fact in the <span class="math inline">\(span(\a,\b)\)</span>.</li>
</ul>
<ol start="2" style="list-style-type: lower-alpha">
<li><span class="math inline">\(\y=\pm 2\\4\\6 \mp\)</span></li>
</ol>
<ul>
<li>We could follow the same procedure as we did in part (a) to learn that the corresponding system is <em>not</em> consistent and thus that <span class="math inline">\(\y\)</span> is not in the <span class="math inline">\(span(\a,\b)\)</span>.</li>
</ul>
</div>
</div>
</div>
</div>
<div id="exercises-3" class="section level2" number="9.3">
<h2><span class="header-section-number">9.3</span> Exercises</h2>
<ol style="list-style-type: decimal">
<li><strong>Six views of matrix multiplication:</strong> Let <span class="math inline">\(\A_{m\times k}\)</span>, <span class="math inline">\(\B_{k\times n}\)</span>, and <span class="math inline">\(\C_{m\times n}\)</span> be matrices such that
<span class="math display">\[\A\B=\C.\]</span></li>
</ol>
<ol style="list-style-type: lower-alpha">
<li>Express the first column of <span class="math inline">\(\C\)</span> as a linear combination of the columns of <span class="math inline">\(\A\)</span>.</li>
<li>Express the first column of <span class="math inline">\(\C\)</span> as a matrix-vector product.</li>
<li>Express <span class="math inline">\(\C\)</span> as a sum of outer products.</li>
<li>Express the first row of <span class="math inline">\(\C\)</span> as a linear combination of the rows of <span class="math inline">\(\B\)</span>.</li>
<li>Express the first row of <span class="math inline">\(\C\)</span> as a matrix-vector product.</li>
<li>Express the element <span class="math inline">\(\C_{ij}\)</span> as an inner product of row or column vectors from <span class="math inline">\(\A\)</span> and <span class="math inline">\(\B\)</span>.</li>
</ol>
<ol start="2" style="list-style-type: decimal">
<li>Determine whether or not the vectors <span class="math display">\[\x_1=\pm 1\\3\\1\mp,\x_2=\pm 0\\1\\1\mp,\x_3=\pm 2\\1\\0\mp\]</span> are linearly independent.</li>
<li>Let <span class="math inline">\(\a=\pm 1\\3\\4 \mp\)</span> and <span class="math inline">\(\b=\pm 3\\0\\1 \mp\)</span>.</li>
</ol>
<ol style="list-style-type: lower-alpha">
<li>Show that the zero vector, <span class="math inline">\(\pm 0\\0\\0 \mp\)</span> is in the <span class="math inline">\(span(\a,\b)\)</span>.</li>
<li>Determine whether or not the vector <span class="math inline">\(\pm 1\\0\\1 \mp\)</span> is in the <span class="math inline">\(span(\a,\b)\)</span>.</li>
</ol>
<ol start="4" style="list-style-type: decimal">
<li>What is the span of the zero vector, <span class="math inline">\(\bo{0}=(0,0,\dots, 0)\)</span>?</li>
<li>Draw the <span class="math inline">\(span(\a,\b)\)</span> if <span class="math inline">\(\a=\pm 1\\2 \mp\)</span> and <span class="math inline">\(\b=\pm 3\\6 \mp\)</span>.</li>
<li>Prove that the span of vectors is a subspace by showing that it satisfies the three conditions from Definition . To make a formal proof, the strategy should be as follows: (1) Take two arbitrary elements from the span and show that when you add them together, the resulting vector is also in the span. (2) Take one arbitrary vector from the span and show that when you multiply it by a constant, the resulting vector is also in the span. (3) Show that the zero vector is contained in the span. You can simply show this fact for the span of two vectors and notice how the concept will hold for more than two vectors.</li>
<li><em>True/False</em> Mark each statement as true or false. Justify your response.</li>
</ol>
<ol style="list-style-type: lower-alpha">
<li>If <span class="math inline">\(\A\x=\b\)</span> has a solution then <span class="math inline">\(\b\)</span> can be written as a linear combination of the columns of <span class="math inline">\(\A\)</span>.</li>
<li>If <span class="math inline">\(\A\x=\b\)</span> has a solution then <span class="math inline">\(\b\)</span> is in the span of the columns of <span class="math inline">\(\A\)</span>.</li>
<li>If <span class="math inline">\(\v_1\)</span> is in the <span class="math inline">\(span(\v_2,\v_3)\)</span>, then <span class="math inline">\(\v_1, \v_2, \,\mbox{ and},\v_3\)</span> form a linearly independent set.</li>
</ol>
<ol start="8" style="list-style-type: decimal">
<li>Two vectors are linearly independent only if they are not perfectly correlated, <span class="math inline">\(-1&lt;\rho&lt;1\)</span>, where <span class="math inline">\(\rho\)</span> is Pearson’s correlation coefficient.</li>
</ol>
</div>
<div id="list-of-key-terms-3" class="section level2 unnumbered">
<h2>List of Key Terms</h2>
<ul>
<li>linearly independent</li>
<li>linearly dependent</li>
<li>full rank</li>
<li>perfect multicollinearity</li>
<li>severe multicollinearity</li>
<li>invertible</li>
<li>nonsingular</li>
</ul>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="lsapp.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="pca.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/shainarace/LinearAlgebra/edit/master/025-linind.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": "https://github.com/shainarace/LinearAlgebra/blob/master/025-linind.Rmd",
"text": null
},
"download": ["bookdownproj.pdf", "bookdownproj.epub"],
"toc": {
"collapse": "subsection",
"scroll_highlight": true
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>

<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 1 Introduction | Linear Algebra for Data Science</title>
  <meta name="description" content="A traditional textbook fused with a collection of data science case studies that was engineered to weave practicality and applied problem solving into a linear algebra curriculum" />
  <meta name="generator" content="bookdown 0.22 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 1 Introduction | Linear Algebra for Data Science" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="A traditional textbook fused with a collection of data science case studies that was engineered to weave practicality and applied problem solving into a linear algebra curriculum" />
  <meta name="github-repo" content="shainarace/linearalgebra" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 1 Introduction | Linear Algebra for Data Science" />
  
  <meta name="twitter:description" content="A traditional textbook fused with a collection of data science case studies that was engineered to weave practicality and applied problem solving into a linear algebra curriculum" />
  

<meta name="author" content="Shaina Race Bennett, PhD" />


<meta name="date" content="2021-07-30" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="index.html"/>
<link rel="next" href="mult.html"/>
<script src="libs/header-attrs-2.6/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>
<script src="libs/htmlwidgets-1.5.3/htmlwidgets.js"></script>
<script src="libs/plotly-binding-4.9.4.1/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/crosstalk-1.1.0.1/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk-1.1.0.1/js/crosstalk.min.js"></script>
<link href="libs/plotly-htmlwidgets-css-1.57.1/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotly-main-1.57.1/plotly-latest.min.js"></script>
<script src="libs/d3-4.5.0/d3.min.js"></script>
<script src="libs/forceNetwork-binding-0.4/forceNetwork.js"></script>
<!DOCTYPE html>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  loader: {load: ['[tex]/cancel', '[tex]/systeme','[tex]/require']},
  TeX: {
    packages: {'[+]': ['cancel','systeme','boldsymbol','require']}
  }
});
</script>


<script type="text/javascript" id="MathJax-script"
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
</script>

<span class="math" style="display:none">
\(\usepackage{amsfonts}
\usepackage{cancel}
\usepackage{amsmath}
\usepackage{systeme}
\usepackage{amsthm}
\usepackage{xcolor}
\usepackage{boldsymbol}
\newenvironment{am}[1]{%
  \left(\begin{array}{@{}*{#1}{c}|c@{}}
}{%
  \end{array}\right)
}
\newcommand{\bordermatrix}[3]{\begin{matrix} ~ & \begin{matrix} #1 \end{matrix} \\ \begin{matrix} #2 \end{matrix}\hspace{-1em} & #3 \end{matrix}}
\newcommand{\eref}[1]{Example~\ref{#1}}
\newcommand{\fref}[1]{Figure~\ref{#1}}
\newcommand{\tref}[1]{Table~\ref{#1}}
\newcommand{\sref}[1]{Section~\ref{#1}}
\newcommand{\cref}[1]{Chapter~\ref{#1}}
\newtheorem{definition}{Definition}
\newtheorem{lemma}{Lemma}
\newtheorem{fact}{Fact}
\newtheorem{thm}{Theorem}
\newtheorem{example}{Example}[section]
\newcommand{\To}{\Rightarrow}
\newcommand{\del}{\nabla}
\renewcommand{\Re}{\mathbb{R}}
\renewcommand{\O}{\mathcal{O}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\ben}{\begin{enumerate}}
\newcommand{\een}{\end{enumerate}}
\newcommand{\eps}{\epsilon}
\newcommand{\cont}{\Rightarrow \Leftarrow}
\newcommand{\back}{\backslash}
\newcommand{\norm}[1]{\|{#1}\|}
\newcommand{\abs}[1]{|{#1}|}
\newcommand{\ip}[1]{\langle{#1}\rangle}
\newcommand{\bo}{\mathbf}
\newcommand{\mean}{\boldsymbol\mu}
\newcommand{\cov}{\boldsymbol\Sigma}
\newcommand{\wt}{\widetilde}
\newcommand{\p}{\textbf{p}}
\newcommand{\ff}{\textbf{f}}
\newcommand{\aj}{\textbf{a}_j}
\newcommand{\ajhat}{\widehat{\textbf{a}_j}}
\newcommand{\I}{\textbf{I}}
\newcommand{\A}{\textbf{A}}
\newcommand{\B}{\textbf{B}}
\newcommand{\bL}{\textbf{L}}
\newcommand{\bP}{\textbf{P}}
\newcommand{\bD}{\textbf{D}}
\newcommand{\bS}{\textbf{S}}
\newcommand{\bW}{\textbf{W}}
\newcommand{\id}{\textbf{I}}
\newcommand{\M}{\textbf{M}}
\renewcommand{\B}{\textbf{B}}
\newcommand{\V}{\textbf{V}}
\newcommand{\U}{\textbf{U}}
\newcommand{\y}{\textbf{y}}
\newcommand{\bv}{\textbf{v}}
\renewcommand{\v}{\textbf{v}}
\newcommand{\cC}{\mathscr{C}}
\newcommand{\e}{\textbf{e}}
\newcommand{\w}{\textbf{w}}
\newcommand{\h}{\textbf{h}}
\renewcommand{\b}{\textbf{b}}
\renewcommand{\a}{\textbf{a}}
\renewcommand{\u}{\textbf{u}}
\newcommand{\C}{\textbf{C}}
\newcommand{\D}{\textbf{D}}
\newcommand{\cc}{\textbf{c}}
\newcommand{\Q}{\textbf{Q}}
\renewcommand{\S}{\textbf{S}}
\newcommand{\X}{\textbf{X}}
\newcommand{\Z}{\textbf{Z}}
\newcommand{\z}{\textbf{z}}
\newcommand{\Y}{\textbf{Y}}
\newcommand{\plane}{\textit{P}}
\newcommand{\mxn}{$m\mbox{x}n$}
\newcommand{\kmeans}{\textit{k}-means\,}
\newcommand{\bbeta}{\boldsymbol\beta}
\newcommand{\ssigma}{\boldsymbol\Sigma}
\newcommand{\xrow}[1]{\mathbf{X}_{{#1}\star}}
\newcommand{\xcol}[1]{\mathbf{X}_{\star{#1}}}
\newcommand{\yrow}[1]{\mathbf{Y}_{{#1}\star}}
\newcommand{\ycol}[1]{\mathbf{Y}_{\star{#1}}}
\newcommand{\crow}[1]{\mathbf{C}_{{#1}\star}}
\newcommand{\ccol}[1]{\mathbf{C}_{\star{#1}}}
\newcommand{\red}[1]{\textcolor{red}{#1}}
\newcommand{\blue}[1]{\textcolor{blue}{#1}}
\newcommand{\arow}[1]{\mathbf{A}_{{#1}\star}}
\newcommand{\acol}[1]{\mathbf{A}_{\star{#1}}}
\newcommand{\brow}[1]{\mathbf{B}_{{#1}\star}}
\newcommand{\bcol}[1]{\mathbf{B}_{\star{#1}}}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}
\renewcommand{\t}{ \indent}
\newcommand{\nt}{ \indent}
\newcommand{\x}{\mathbf{x}}
\renewcommand{\Y}{\mathbf{Y}}
\newcommand{\ep}{\mathbf{\epsilon}}
\renewcommand{\pm}{\left(\begin{matrix}}
\renewcommand{\mp}{\end{matrix}\right)}
\newcommand{\bm}{\bordermatrix}
\usepackage{pdfpages,cancel}
\newenvironment{code}{\Verbatim [formatcom=\color{blue}]}{\endVerbatim}
\)
</span>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><center><img src="figs/matrixlogo.jpg" width="50"></center></li>
<li><center><strong> Linear Algebra for Data Science </strong></center></li>
<li><center><strong> with examples in R </strong></center></li>

<li class="divider"></li>
<li><a href="index.html#section"></a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#structure-of-the-book"><i class="fa fa-check"></i>Structure of the book</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#about-the-author"><i class="fa fa-check"></i>About the author</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#acknowledgements"><i class="fa fa-check"></i>Acknowledgements</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1" data-path="intro.html"><a href="intro.html#what-is-linear-algebra"><i class="fa fa-check"></i><b>1.1</b> What is Linear Algebra?</a></li>
<li class="chapter" data-level="1.2" data-path="intro.html"><a href="intro.html#why-linear-algebra"><i class="fa fa-check"></i><b>1.2</b> Why Linear Algebra</a></li>
<li class="chapter" data-level="1.3" data-path="intro.html"><a href="intro.html#describing-matrices-and-vectors"><i class="fa fa-check"></i><b>1.3</b> Describing Matrices and Vectors</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="intro.html"><a href="intro.html#dimensionsize-of-a-matrix"><i class="fa fa-check"></i><b>1.3.1</b> Dimension/Size of a Matrix</a></li>
<li class="chapter" data-level="1.3.2" data-path="intro.html"><a href="intro.html#ij-notation"><i class="fa fa-check"></i><b>1.3.2</b> <span class="math inline">\((i,j)\)</span> Notation</a></li>
<li class="chapter" data-level="" data-path="intro.html"><a href="intro.html#example-defining-social-networks"><i class="fa fa-check"></i>Example: Defining social networks</a></li>
<li class="chapter" data-level="1.3.3" data-path="intro.html"><a href="intro.html#introcorr"><i class="fa fa-check"></i><b>1.3.3</b> Example: Correlation matrices</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="intro.html"><a href="intro.html#vectors"><i class="fa fa-check"></i><b>1.4</b> Vectors</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="intro.html"><a href="intro.html#vector-geometry-n-space"><i class="fa fa-check"></i><b>1.4.1</b> Vector Geometry: <span class="math inline">\(n\)</span>-space</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="intro.html"><a href="intro.html#matrix-operations"><i class="fa fa-check"></i><b>1.5</b> Matrix Operations</a>
<ul>
<li class="chapter" data-level="1.5.1" data-path="intro.html"><a href="intro.html#transpose"><i class="fa fa-check"></i><b>1.5.1</b> Transpose</a></li>
<li class="chapter" data-level="1.5.2" data-path="intro.html"><a href="intro.html#trace-of-a-matrix"><i class="fa fa-check"></i><b>1.5.2</b> Trace of a Matrix</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="intro.html"><a href="intro.html#special"><i class="fa fa-check"></i><b>1.6</b> Special Matrices and Vectors</a></li>
<li class="chapter" data-level="1.7" data-path="intro.html"><a href="intro.html#summary-of-conventional-notation"><i class="fa fa-check"></i><b>1.7</b> Summary of Conventional Notation</a></li>
<li class="chapter" data-level="1.8" data-path="intro.html"><a href="intro.html#exercises"><i class="fa fa-check"></i><b>1.8</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="mult.html"><a href="mult.html"><i class="fa fa-check"></i><b>2</b> Matrix Arithmetic</a>
<ul>
<li class="chapter" data-level="2.1" data-path="mult.html"><a href="mult.html#matrix-addition-subtraction-and-scalar-multiplication"><i class="fa fa-check"></i><b>2.1</b> Matrix Addition, Subtraction, and Scalar Multiplication</a></li>
<li class="chapter" data-level="2.2" data-path="mult.html"><a href="mult.html#sec:vectoradd"><i class="fa fa-check"></i><b>2.2</b> Geometry of Vector Addition and Scalar Multiplication</a></li>
<li class="chapter" data-level="2.3" data-path="mult.html"><a href="mult.html#linear-combinations"><i class="fa fa-check"></i><b>2.3</b> Linear Combinations</a></li>
<li class="chapter" data-level="2.4" data-path="mult.html"><a href="mult.html#matrix-multiplication"><i class="fa fa-check"></i><b>2.4</b> Matrix Multiplication</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="mult.html"><a href="mult.html#the-inner-product"><i class="fa fa-check"></i><b>2.4.1</b> The Inner Product</a></li>
<li class="chapter" data-level="2.4.2" data-path="mult.html"><a href="mult.html#matrix-product"><i class="fa fa-check"></i><b>2.4.2</b> Matrix Product</a></li>
<li class="chapter" data-level="2.4.3" data-path="mult.html"><a href="mult.html#matrix-vector-product"><i class="fa fa-check"></i><b>2.4.3</b> Matrix-Vector Product</a></li>
<li class="chapter" data-level="" data-path="mult.html"><a href="mult.html#linear-combination-view-of-matrix-products"><i class="fa fa-check"></i>Linear Combination view of Matrix Products</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="mult.html"><a href="mult.html#vector-outer-products"><i class="fa fa-check"></i><b>2.5</b> Vector Outer Products</a></li>
<li class="chapter" data-level="2.6" data-path="mult.html"><a href="mult.html#the-identity-and-the-matrix-inverse"><i class="fa fa-check"></i><b>2.6</b> The Identity and the Matrix Inverse</a></li>
<li class="chapter" data-level="2.7" data-path="mult.html"><a href="mult.html#exercises-1"><i class="fa fa-check"></i><b>2.7</b> Exercises</a></li>
<li class="chapter" data-level="" data-path="mult.html"><a href="mult.html#list-of-key-terms"><i class="fa fa-check"></i>List of Key Terms</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="multapp.html"><a href="multapp.html"><i class="fa fa-check"></i><b>3</b> Applications of Matrix Multiplication</a>
<ul>
<li class="chapter" data-level="3.1" data-path="multapp.html"><a href="multapp.html#systems-of-equations"><i class="fa fa-check"></i><b>3.1</b> Systems of Equations</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="multapp.html"><a href="multapp.html#big-systems-of-equations"><i class="fa fa-check"></i><b>3.1.1</b> <em>Big</em> Systems of Equations</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="multapp.html"><a href="multapp.html#regression-analysis"><i class="fa fa-check"></i><b>3.2</b> Regression Analysis</a></li>
<li class="chapter" data-level="3.3" data-path="multapp.html"><a href="multapp.html#linear-combinations-1"><i class="fa fa-check"></i><b>3.3</b> Linear Combinations</a></li>
<li class="chapter" data-level="3.4" data-path="multapp.html"><a href="multapp.html#multapp-ex"><i class="fa fa-check"></i><b>3.4</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="r-programming-basics.html"><a href="r-programming-basics.html"><i class="fa fa-check"></i><b>4</b> R Programming Basics</a></li>
<li class="chapter" data-level="5" data-path="solvesys.html"><a href="solvesys.html"><i class="fa fa-check"></i><b>5</b> Solving Systems of Equations</a>
<ul>
<li class="chapter" data-level="5.1" data-path="solvesys.html"><a href="solvesys.html#gaussian-elimination"><i class="fa fa-check"></i><b>5.1</b> Gaussian Elimination</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="solvesys.html"><a href="solvesys.html#row-operations"><i class="fa fa-check"></i><b>5.1.1</b> Row Operations</a></li>
<li class="chapter" data-level="5.1.2" data-path="solvesys.html"><a href="solvesys.html#the-augmented-matrix"><i class="fa fa-check"></i><b>5.1.2</b> The Augmented Matrix</a></li>
<li class="chapter" data-level="5.1.3" data-path="solvesys.html"><a href="solvesys.html#gaussian-elimination-summary"><i class="fa fa-check"></i><b>5.1.3</b> Gaussian Elimination Summary</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="solvesys.html"><a href="solvesys.html#gauss-jordan-elimination"><i class="fa fa-check"></i><b>5.2</b> Gauss-Jordan Elimination</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="solvesys.html"><a href="solvesys.html#gauss-jordan-elimination-summary"><i class="fa fa-check"></i><b>5.2.1</b> Gauss-Jordan Elimination Summary</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="solvesys.html"><a href="solvesys.html#three-types-of-systems"><i class="fa fa-check"></i><b>5.3</b> Three Types of Systems</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="solvesys.html"><a href="solvesys.html#uniquesol"><i class="fa fa-check"></i><b>5.3.1</b> The Unique Solution Case</a></li>
<li class="chapter" data-level="5.3.2" data-path="solvesys.html"><a href="solvesys.html#inconsistent"><i class="fa fa-check"></i><b>5.3.2</b> The Inconsistent Case</a></li>
<li class="chapter" data-level="5.3.3" data-path="solvesys.html"><a href="solvesys.html#infinitesol"><i class="fa fa-check"></i><b>5.3.3</b> The Infinite Solutions Case</a></li>
<li class="chapter" data-level="5.3.4" data-path="solvesys.html"><a href="solvesys.html#matrix-rank"><i class="fa fa-check"></i><b>5.3.4</b> Matrix Rank</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="solvesys.html"><a href="solvesys.html#solving-matrix-equations"><i class="fa fa-check"></i><b>5.4</b> Solving Matrix Equations</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="solvesys.html"><a href="solvesys.html#solving-for-the-inverse-of-a-matrix"><i class="fa fa-check"></i><b>5.4.1</b> Solving for the Inverse of a Matrix</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="solvesys.html"><a href="solvesys.html#exercises-2"><i class="fa fa-check"></i><b>5.5</b> Exercises</a></li>
<li class="chapter" data-level="5.6" data-path="solvesys.html"><a href="solvesys.html#list-of-key-terms-1"><i class="fa fa-check"></i><b>5.6</b> List of Key Terms</a></li>
<li class="chapter" data-level="5.7" data-path="solvesys.html"><a href="solvesys.html#gauss-jordan-elimination-in-r"><i class="fa fa-check"></i><b>5.7</b> Gauss-Jordan Elimination in R</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="norms.html"><a href="norms.html"><i class="fa fa-check"></i><b>6</b> Norms, Similarity, and Distance</a>
<ul>
<li class="chapter" data-level="6.1" data-path="norms.html"><a href="norms.html#sec-norms"><i class="fa fa-check"></i><b>6.1</b> Norms and Distances</a></li>
<li class="chapter" data-level="6.2" data-path="norms.html"><a href="norms.html#other-useful-norms-and-distances"><i class="fa fa-check"></i><b>6.2</b> Other useful norms and distances</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="norms.html"><a href="norms.html#norm-star_1."><i class="fa fa-check"></i><b>6.2.1</b> 1-norm, <span class="math inline">\(\|\star\|_1\)</span>.</a></li>
<li class="chapter" data-level="6.2.2" data-path="norms.html"><a href="norms.html#infty-norm-star_infty."><i class="fa fa-check"></i><b>6.2.2</b> <span class="math inline">\(\infty\)</span>-norm, <span class="math inline">\(\|\star\|_{\infty}\)</span>.</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="norms.html"><a href="norms.html#inner-products"><i class="fa fa-check"></i><b>6.3</b> Inner Products</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="norms.html"><a href="norms.html#covariance"><i class="fa fa-check"></i><b>6.3.1</b> Covariance</a></li>
<li class="chapter" data-level="6.3.2" data-path="norms.html"><a href="norms.html#mahalanobis-distance"><i class="fa fa-check"></i><b>6.3.2</b> Mahalanobis Distance</a></li>
<li class="chapter" data-level="6.3.3" data-path="norms.html"><a href="norms.html#angular-distance"><i class="fa fa-check"></i><b>6.3.3</b> Angular Distance</a></li>
<li class="chapter" data-level="6.3.4" data-path="norms.html"><a href="norms.html#correlation"><i class="fa fa-check"></i><b>6.3.4</b> Correlation</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="norms.html"><a href="norms.html#exercises-3"><i class="fa fa-check"></i><b>6.4</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="linind.html"><a href="linind.html"><i class="fa fa-check"></i><b>7</b> Linear Independence</a>
<ul>
<li class="chapter" data-level="7.1" data-path="linind.html"><a href="linind.html#linear-independence"><i class="fa fa-check"></i><b>7.1</b> Linear Independence</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="linind.html"><a href="linind.html#determining-linear-independence"><i class="fa fa-check"></i><b>7.1.1</b> Determining Linear Independence</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="linind.html"><a href="linind.html#span"><i class="fa fa-check"></i><b>7.2</b> Span of Vectors</a></li>
<li class="chapter" data-level="7.3" data-path="linind.html"><a href="linind.html#exercises-4"><i class="fa fa-check"></i><b>7.3</b> Exercises</a></li>
<li class="chapter" data-level="" data-path="linind.html"><a href="linind.html#list-of-key-terms-2"><i class="fa fa-check"></i>List of Key Terms</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="basis.html"><a href="basis.html"><i class="fa fa-check"></i><b>8</b> Basis and Change of Basis</a>
<ul>
<li class="chapter" data-level="8.1" data-path="basis.html"><a href="basis.html#exercises-5"><i class="fa fa-check"></i><b>8.1</b> Exercises</a></li>
<li class="chapter" data-level="" data-path="basis.html"><a href="basis.html#list-of-key-terms-3"><i class="fa fa-check"></i>List of Key Terms</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="orthog.html"><a href="orthog.html"><i class="fa fa-check"></i><b>9</b> Orthogonality</a>
<ul>
<li class="chapter" data-level="9.1" data-path="orthog.html"><a href="orthog.html#orthonormal-basis"><i class="fa fa-check"></i><b>9.1</b> Orthonormal Basis</a></li>
<li class="chapter" data-level="9.2" data-path="orthog.html"><a href="orthog.html#orthogonal-projection"><i class="fa fa-check"></i><b>9.2</b> Orthogonal Projection</a></li>
<li class="chapter" data-level="9.3" data-path="orthog.html"><a href="orthog.html#why"><i class="fa fa-check"></i><b>9.3</b> Why??</a></li>
<li class="chapter" data-level="9.4" data-path="orthog.html"><a href="orthog.html#exercises-6"><i class="fa fa-check"></i><b>9.4</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="leastsquares.html"><a href="leastsquares.html"><i class="fa fa-check"></i><b>10</b> Least Squares</a>
<ul>
<li class="chapter" data-level="10.1" data-path="leastsquares.html"><a href="leastsquares.html#introducing-error"><i class="fa fa-check"></i><b>10.1</b> Introducing Error</a></li>
<li class="chapter" data-level="10.2" data-path="leastsquares.html"><a href="leastsquares.html#why-the-normal-equations"><i class="fa fa-check"></i><b>10.2</b> Why the normal equations?</a>
<ul>
<li class="chapter" data-level="10.2.1" data-path="leastsquares.html"><a href="leastsquares.html#geometrical-interpretation"><i class="fa fa-check"></i><b>10.2.1</b> Geometrical Interpretation</a></li>
<li class="chapter" data-level="10.2.2" data-path="leastsquares.html"><a href="leastsquares.html#calculus-derivation"><i class="fa fa-check"></i><b>10.2.2</b> Calculus Derivation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="lsapp.html"><a href="lsapp.html"><i class="fa fa-check"></i><b>11</b> Applications of Least Squares</a>
<ul>
<li class="chapter" data-level="11.1" data-path="lsapp.html"><a href="lsapp.html#simple-linear-regression"><i class="fa fa-check"></i><b>11.1</b> Simple Linear Regression</a>
<ul>
<li class="chapter" data-level="11.1.1" data-path="lsapp.html"><a href="lsapp.html#cars-data"><i class="fa fa-check"></i><b>11.1.1</b> Cars Data</a></li>
<li class="chapter" data-level="11.1.2" data-path="lsapp.html"><a href="lsapp.html#setting-up-the-normal-equations"><i class="fa fa-check"></i><b>11.1.2</b> Setting up the Normal Equations</a></li>
<li class="chapter" data-level="11.1.3" data-path="lsapp.html"><a href="lsapp.html#solving-for-parameter-estimates-and-statistics"><i class="fa fa-check"></i><b>11.1.3</b> Solving for Parameter Estimates and Statistics</a></li>
<li class="chapter" data-level="11.1.4" data-path="lsapp.html"><a href="lsapp.html#ols-in-r-via-lm"><i class="fa fa-check"></i><b>11.1.4</b> OLS in R via <code>lm()</code></a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="lsapp.html"><a href="lsapp.html#multiple-linear-regression"><i class="fa fa-check"></i><b>11.2</b> Multiple Linear Regression</a>
<ul>
<li class="chapter" data-level="11.2.1" data-path="lsapp.html"><a href="lsapp.html#bike-sharing-dataset"><i class="fa fa-check"></i><b>11.2.1</b> Bike Sharing Dataset</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="eigen.html"><a href="eigen.html"><i class="fa fa-check"></i><b>12</b> Eigenvalues and Eigenvectors</a>
<ul>
<li class="chapter" data-level="12.1" data-path="eigen.html"><a href="eigen.html#diagonalization"><i class="fa fa-check"></i><b>12.1</b> Diagonalization</a></li>
<li class="chapter" data-level="12.2" data-path="eigen.html"><a href="eigen.html#geometric-interpretation-of-eigenvalues-and-eigenvectors"><i class="fa fa-check"></i><b>12.2</b> Geometric Interpretation of Eigenvalues and Eigenvectors</a></li>
<li class="chapter" data-level="12.3" data-path="eigen.html"><a href="eigen.html#exercises-7"><i class="fa fa-check"></i><b>12.3</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="pca.html"><a href="pca.html"><i class="fa fa-check"></i><b>13</b> Principal Components Analysis</a>
<ul>
<li class="chapter" data-level="13.1" data-path="pca.html"><a href="pca.html#geometrical-comparison-with-least-squares"><i class="fa fa-check"></i><b>13.1</b> Geometrical comparison with Least Squares</a></li>
<li class="chapter" data-level="13.2" data-path="pca.html"><a href="pca.html#covariance-or-correlation-matrix"><i class="fa fa-check"></i><b>13.2</b> Covariance or Correlation Matrix?</a></li>
<li class="chapter" data-level="13.3" data-path="pca.html"><a href="pca.html#pca-in-r"><i class="fa fa-check"></i><b>13.3</b> PCA in R</a>
<ul>
<li class="chapter" data-level="13.3.1" data-path="pca.html"><a href="pca.html#covariance-pca"><i class="fa fa-check"></i><b>13.3.1</b> Covariance PCA</a></li>
<li class="chapter" data-level="13.3.2" data-path="pca.html"><a href="pca.html#principal-components-loadings-and-variance-explained"><i class="fa fa-check"></i><b>13.3.2</b> Principal Components, Loadings, and Variance Explained</a></li>
<li class="chapter" data-level="13.3.3" data-path="pca.html"><a href="pca.html#scores-and-pca-projection"><i class="fa fa-check"></i><b>13.3.3</b> Scores and PCA Projection</a></li>
<li class="chapter" data-level="13.3.4" data-path="pca.html"><a href="pca.html#pca-functions-in-r"><i class="fa fa-check"></i><b>13.3.4</b> PCA functions in R</a></li>
<li class="chapter" data-level="13.3.5" data-path="pca.html"><a href="pca.html#the-biplot"><i class="fa fa-check"></i><b>13.3.5</b> The Biplot</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="pca.html"><a href="pca.html#variable-clustering-with-pca"><i class="fa fa-check"></i><b>13.4</b> Variable Clustering with PCA</a>
<ul>
<li class="chapter" data-level="13.4.1" data-path="pca.html"><a href="pca.html#correlation-pca"><i class="fa fa-check"></i><b>13.4.1</b> Correlation PCA</a></li>
<li class="chapter" data-level="13.4.2" data-path="pca.html"><a href="pca.html#which-projection-is-better"><i class="fa fa-check"></i><b>13.4.2</b> Which Projection is Better?</a></li>
<li class="chapter" data-level="13.4.3" data-path="pca.html"><a href="pca.html#beware-of-biplots"><i class="fa fa-check"></i><b>13.4.3</b> Beware of biplots</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="14" data-path="pcaapp.html"><a href="pcaapp.html"><i class="fa fa-check"></i><b>14</b> Applications of Principal Components</a>
<ul>
<li class="chapter" data-level="14.1" data-path="pcaapp.html"><a href="pcaapp.html#dimension-reduction"><i class="fa fa-check"></i><b>14.1</b> Dimension reduction</a>
<ul>
<li class="chapter" data-level="14.1.1" data-path="pcaapp.html"><a href="pcaapp.html#feature-selection"><i class="fa fa-check"></i><b>14.1.1</b> Feature Selection</a></li>
<li class="chapter" data-level="14.1.2" data-path="pcaapp.html"><a href="pcaapp.html#feature-extraction"><i class="fa fa-check"></i><b>14.1.2</b> Feature Extraction</a></li>
</ul></li>
<li class="chapter" data-level="14.2" data-path="pcaapp.html"><a href="pcaapp.html#exploratory-analysis"><i class="fa fa-check"></i><b>14.2</b> Exploratory Analysis</a>
<ul>
<li class="chapter" data-level="14.2.1" data-path="pcaapp.html"><a href="pcaapp.html#uk-food-consumption"><i class="fa fa-check"></i><b>14.2.1</b> UK Food Consumption</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="pcaapp.html"><a href="pcaapp.html#fifa-soccer-players"><i class="fa fa-check"></i><b>14.3</b> FIFA Soccer Players</a></li>
<li class="chapter" data-level="14.4" data-path="pcaapp.html"><a href="pcaapp.html#cancer-genetics"><i class="fa fa-check"></i><b>14.4</b> Cancer Genetics</a>
<ul>
<li class="chapter" data-level="14.4.1" data-path="pcaapp.html"><a href="pcaapp.html#computing-the-pca"><i class="fa fa-check"></i><b>14.4.1</b> Computing the PCA</a></li>
<li class="chapter" data-level="14.4.2" data-path="pcaapp.html"><a href="pcaapp.html#d-plot-with-package"><i class="fa fa-check"></i><b>14.4.2</b> 3D plot with  package</a></li>
<li class="chapter" data-level="14.4.3" data-path="pcaapp.html"><a href="pcaapp.html#d-plot-with-package-1"><i class="fa fa-check"></i><b>14.4.3</b> 3D plot with  package</a></li>
<li class="chapter" data-level="14.4.4" data-path="pcaapp.html"><a href="pcaapp.html#variance-explained"><i class="fa fa-check"></i><b>14.4.4</b> Variance explained</a></li>
<li class="chapter" data-level="14.4.5" data-path="pcaapp.html"><a href="pcaapp.html#using-correlation-pca"><i class="fa fa-check"></i><b>14.4.5</b> Using Correlation PCA</a></li>
<li class="chapter" data-level="14.4.6" data-path="pcaapp.html"><a href="pcaapp.html#range-standardization-as-an-alternative-to-covariance-pca"><i class="fa fa-check"></i><b>14.4.6</b> Range standardization as an alternative to covariance PCA</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="15" data-path="svd.html"><a href="svd.html"><i class="fa fa-check"></i><b>15</b> The Singular Value Decomposition (SVD)</a>
<ul>
<li class="chapter" data-level="15.1" data-path="svd.html"><a href="svd.html#resolving-a-matrix-into-components"><i class="fa fa-check"></i><b>15.1</b> Resolving a Matrix into Components</a></li>
<li class="chapter" data-level="15.2" data-path="svd.html"><a href="svd.html#data-compression"><i class="fa fa-check"></i><b>15.2</b> Data Compression</a></li>
<li class="chapter" data-level="15.3" data-path="svd.html"><a href="svd.html#noise-reduction"><i class="fa fa-check"></i><b>15.3</b> Noise Reduction</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="svdapp.html"><a href="svdapp.html"><i class="fa fa-check"></i><b>16</b> Applications of SVD</a>
<ul>
<li class="chapter" data-level="16.1" data-path="svdapp.html"><a href="svdapp.html#tm"><i class="fa fa-check"></i><b>16.1</b> Text Mining</a>
<ul>
<li class="chapter" data-level="16.1.1" data-path="svdapp.html"><a href="svdapp.html#note-about-rows-vs.-columns"><i class="fa fa-check"></i><b>16.1.1</b> Note About Rows vs. Columns</a></li>
<li class="chapter" data-level="16.1.2" data-path="svdapp.html"><a href="svdapp.html#term-weighting"><i class="fa fa-check"></i><b>16.1.2</b> Term Weighting</a></li>
<li class="chapter" data-level="16.1.3" data-path="svdapp.html"><a href="svdapp.html#other-considerations"><i class="fa fa-check"></i><b>16.1.3</b> Other Considerations</a></li>
<li class="chapter" data-level="16.1.4" data-path="svdapp.html"><a href="svdapp.html#latent-semantic-indexing"><i class="fa fa-check"></i><b>16.1.4</b> Latent Semantic Indexing</a></li>
<li class="chapter" data-level="16.1.5" data-path="svdapp.html"><a href="svdapp.html#example"><i class="fa fa-check"></i><b>16.1.5</b> Example</a></li>
</ul></li>
<li class="chapter" data-level="16.2" data-path="svdapp.html"><a href="svdapp.html#rappasvd"><i class="fa fa-check"></i><b>16.2</b> Image Compression</a>
<ul>
<li class="chapter" data-level="16.2.1" data-path="svdapp.html"><a href="svdapp.html#image-data-in-r"><i class="fa fa-check"></i><b>16.2.1</b> Image data in R</a></li>
<li class="chapter" data-level="16.2.2" data-path="svdapp.html"><a href="svdapp.html#computing-the-svd-of-dr.-rappa"><i class="fa fa-check"></i><b>16.2.2</b> Computing the SVD of Dr. Rappa</a></li>
<li class="chapter" data-level="16.2.3" data-path="svdapp.html"><a href="svdapp.html#the-noise"><i class="fa fa-check"></i><b>16.2.3</b> The Noise</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="17" data-path="fa.html"><a href="fa.html"><i class="fa fa-check"></i><b>17</b> Factor Analysis</a>
<ul>
<li class="chapter" data-level="17.1" data-path="fa.html"><a href="fa.html#assumptions-of-factor-analysis"><i class="fa fa-check"></i><b>17.1</b> Assumptions of Factor Analysis</a></li>
<li class="chapter" data-level="17.2" data-path="fa.html"><a href="fa.html#determining-factorability"><i class="fa fa-check"></i><b>17.2</b> Determining Factorability</a>
<ul>
<li class="chapter" data-level="17.2.1" data-path="fa.html"><a href="fa.html#visual-examination-of-correlation-matrix"><i class="fa fa-check"></i><b>17.2.1</b> Visual Examination of Correlation Matrix</a></li>
<li class="chapter" data-level="17.2.2" data-path="fa.html"><a href="fa.html#barletts-sphericity-test"><i class="fa fa-check"></i><b>17.2.2</b> Barlett’s Sphericity Test</a></li>
<li class="chapter" data-level="17.2.3" data-path="fa.html"><a href="fa.html#kaiser-meyer-olkin-kmo-measure-of-sampling-adequacy"><i class="fa fa-check"></i><b>17.2.3</b> Kaiser-Meyer-Olkin (KMO) Measure of Sampling Adequacy</a></li>
</ul></li>
<li class="chapter" data-level="17.3" data-path="fa.html"><a href="fa.html#communalities"><i class="fa fa-check"></i><b>17.3</b> Communalities</a></li>
<li class="chapter" data-level="17.4" data-path="fa.html"><a href="fa.html#number-of-factors"><i class="fa fa-check"></i><b>17.4</b> Number of Factors</a></li>
<li class="chapter" data-level="17.5" data-path="fa.html"><a href="fa.html#rotation-of-factors"><i class="fa fa-check"></i><b>17.5</b> Rotation of Factors</a></li>
<li class="chapter" data-level="17.6" data-path="fa.html"><a href="fa.html#fa-apps"><i class="fa fa-check"></i><b>17.6</b> Methods of Factor Analysis</a>
<ul>
<li class="chapter" data-level="17.6.1" data-path="fa.html"><a href="fa.html#pca-rotations"><i class="fa fa-check"></i><b>17.6.1</b> PCA Rotations</a></li>
</ul></li>
<li class="chapter" data-level="17.7" data-path="fa.html"><a href="fa.html#case-study-personality-tests"><i class="fa fa-check"></i><b>17.7</b> Case Study: Personality Tests</a>
<ul>
<li class="chapter" data-level="17.7.1" data-path="fa.html"><a href="fa.html#raw-pca-factors"><i class="fa fa-check"></i><b>17.7.1</b> Raw PCA Factors</a></li>
<li class="chapter" data-level="17.7.2" data-path="fa.html"><a href="fa.html#rotated-principal-components"><i class="fa fa-check"></i><b>17.7.2</b> Rotated Principal Components</a></li>
<li class="chapter" data-level="17.7.3" data-path="fa.html"><a href="fa.html#visualizing-rotation-via-biplots"><i class="fa fa-check"></i><b>17.7.3</b> Visualizing Rotation via BiPlots</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="18" data-path="otherdimred.html"><a href="otherdimred.html"><i class="fa fa-check"></i><b>18</b> Dimension Reduction for Visualization</a>
<ul>
<li class="chapter" data-level="18.1" data-path="otherdimred.html"><a href="otherdimred.html#multidimensional-scaling"><i class="fa fa-check"></i><b>18.1</b> Multidimensional Scaling</a>
<ul>
<li class="chapter" data-level="18.1.1" data-path="otherdimred.html"><a href="otherdimred.html#mds-of-leukemia-dataset"><i class="fa fa-check"></i><b>18.1.1</b> MDS of Leukemia dataset</a></li>
<li class="chapter" data-level="" data-path="otherdimred.html"><a href="otherdimred.html#a-note-on-standardization"><i class="fa fa-check"></i>A note on standardization</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="19" data-path="sna.html"><a href="sna.html"><i class="fa fa-check"></i><b>19</b> Social Network Analysis</a>
<ul>
<li class="chapter" data-level="19.1" data-path="sna.html"><a href="sna.html#working-with-network-data"><i class="fa fa-check"></i><b>19.1</b> Working with Network Data</a></li>
<li class="chapter" data-level="19.2" data-path="sna.html"><a href="sna.html#network-visualization---igraph-package"><i class="fa fa-check"></i><b>19.2</b> Network Visualization - <code>igraph</code> package</a>
<ul>
<li class="chapter" data-level="19.2.1" data-path="sna.html"><a href="sna.html#adding-attribute-information-to-your-visualization"><i class="fa fa-check"></i><b>19.2.1</b> Adding attribute information to your visualization</a></li>
<li class="chapter" data-level="19.2.2" data-path="sna.html"><a href="sna.html#preparing-the-data-for-networkd3"><i class="fa fa-check"></i><b>19.2.2</b> Preparing the data for <code>networkD3</code></a></li>
<li class="chapter" data-level="19.2.3" data-path="sna.html"><a href="sna.html#creating-an-interactive-visualization-with-networkd3"><i class="fa fa-check"></i><b>19.2.3</b> Creating an Interactive Visualization with <code>networkD3</code></a></li>
<li class="chapter" data-level="19.2.4" data-path="sna.html"><a href="sna.html#saving-your-interactive-visualization-to-.html"><i class="fa fa-check"></i><b>19.2.4</b> Saving your Interactive Visualization to .html</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>Clustering</b></span></li>
<li class="chapter" data-level="20" data-path="clusintro.html"><a href="clusintro.html"><i class="fa fa-check"></i><b>20</b> Introduction</a>
<ul>
<li class="chapter" data-level="20.1" data-path="clusintro.html"><a href="clusintro.html#mathematical-setup"><i class="fa fa-check"></i><b>20.1</b> Mathematical Setup</a>
<ul>
<li class="chapter" data-level="20.1.1" data-path="clusintro.html"><a href="clusintro.html#data"><i class="fa fa-check"></i><b>20.1.1</b> Data</a></li>
</ul></li>
<li class="chapter" data-level="20.2" data-path="clusintro.html"><a href="clusintro.html#the-number-of-clusters-k"><i class="fa fa-check"></i><b>20.2</b> The Number of Clusters, <span class="math inline">\(k\)</span></a></li>
<li class="chapter" data-level="20.3" data-path="clusintro.html"><a href="clusintro.html#partitioning-of-graphs-and-networks"><i class="fa fa-check"></i><b>20.3</b> Partitioning of Graphs and Networks</a></li>
<li class="chapter" data-level="20.4" data-path="clusintro.html"><a href="clusintro.html#history-of-data-clustering"><i class="fa fa-check"></i><b>20.4</b> History of Data Clustering</a></li>
</ul></li>
<li class="chapter" data-level="21" data-path="clusteralgos.html"><a href="clusteralgos.html"><i class="fa fa-check"></i><b>21</b> Algorithms for Data Clustering</a>
<ul>
<li class="chapter" data-level="21.1" data-path="clusteralgos.html"><a href="clusteralgos.html#hc"><i class="fa fa-check"></i><b>21.1</b> Hierarchical Algorithms</a>
<ul>
<li class="chapter" data-level="21.1.1" data-path="clusteralgos.html"><a href="clusteralgos.html#agglomerative-hierarchical-clustering"><i class="fa fa-check"></i><b>21.1.1</b> Agglomerative Hierarchical Clustering</a></li>
<li class="chapter" data-level="21.1.2" data-path="clusteralgos.html"><a href="clusteralgos.html#principal-direction-divisive-partitioning-pddp"><i class="fa fa-check"></i><b>21.1.2</b> Principal Direction Divisive Partitioning (PDDP)</a></li>
</ul></li>
<li class="chapter" data-level="21.2" data-path="clusteralgos.html"><a href="clusteralgos.html#kmeanshistory"><i class="fa fa-check"></i><b>21.2</b> Iterative Partitional Algorithms</a>
<ul>
<li class="chapter" data-level="21.2.1" data-path="clusteralgos.html"><a href="clusteralgos.html#early-partitional-algorithms"><i class="fa fa-check"></i><b>21.2.1</b> Early Partitional Algorithms</a></li>
<li class="chapter" data-level="21.2.2" data-path="clusteralgos.html"><a href="clusteralgos.html#kmeans"><i class="fa fa-check"></i><b>21.2.2</b> <span class="math inline">\(k\)</span>-means</a></li>
<li class="chapter" data-level="21.2.3" data-path="clusteralgos.html"><a href="clusteralgos.html#the-expectation-maximization-em-clustering-algorithm"><i class="fa fa-check"></i><b>21.2.3</b> The Expectation-Maximization (EM) Clustering Algorithm</a></li>
</ul></li>
<li class="chapter" data-level="21.3" data-path="clusteralgos.html"><a href="clusteralgos.html#density-search-algorithms"><i class="fa fa-check"></i><b>21.3</b> Density Search Algorithms</a>
<ul>
<li class="chapter" data-level="21.3.1" data-path="clusteralgos.html"><a href="clusteralgos.html#density-based-spacial-clustering-of-applications-with-noise-dbscan"><i class="fa fa-check"></i><b>21.3.1</b> Density Based Spacial Clustering of Applications with Noise (DBSCAN)</a></li>
</ul></li>
<li class="chapter" data-level="21.4" data-path="clusteralgos.html"><a href="clusteralgos.html#conclusion"><i class="fa fa-check"></i><b>21.4</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="22" data-path="chap1-5.html"><a href="chap1-5.html"><i class="fa fa-check"></i><b>22</b> Algorithms for Graph Partitioning</a>
<ul>
<li class="chapter" data-level="22.1" data-path="chap1-5.html"><a href="chap1-5.html#spectral"><i class="fa fa-check"></i><b>22.1</b> Spectral Clustering</a></li>
<li class="chapter" data-level="22.2" data-path="chap1-5.html"><a href="chap1-5.html#fiedler-partitioning"><i class="fa fa-check"></i><b>22.2</b> Fiedler Partitioning</a>
<ul>
<li class="chapter" data-level="22.2.1" data-path="chap1-5.html"><a href="chap1-5.html#linear-algebraic-motivation-for-the-fiedler-vector"><i class="fa fa-check"></i><b>22.2.1</b> Linear Algebraic Motivation for the Fiedler vector</a></li>
<li class="chapter" data-level="22.2.2" data-path="chap1-5.html"><a href="chap1-5.html#graph-cuts"><i class="fa fa-check"></i><b>22.2.2</b> Graph Cuts</a></li>
<li class="chapter" data-level="22.2.3" data-path="chap1-5.html"><a href="chap1-5.html#pic"><i class="fa fa-check"></i><b>22.2.3</b> Power Iteration Clustering</a></li>
<li class="chapter" data-level="22.2.4" data-path="chap1-5.html"><a href="chap1-5.html#modularity"><i class="fa fa-check"></i><b>22.2.4</b> Clustering via Modularity Maximization</a></li>
</ul></li>
<li class="chapter" data-level="22.3" data-path="chap1-5.html"><a href="chap1-5.html#stochastic-clustering"><i class="fa fa-check"></i><b>22.3</b> Stochastic Clustering</a>
<ul>
<li class="chapter" data-level="22.3.1" data-path="chap1-5.html"><a href="chap1-5.html#stochastic-clustering-algorithm-sca"><i class="fa fa-check"></i><b>22.3.1</b> Stochastic Clustering Algorithm (SCA)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="23" data-path="validation.html"><a href="validation.html"><i class="fa fa-check"></i><b>23</b> Cluster Validation</a>
<ul>
<li class="chapter" data-level="23.1" data-path="validation.html"><a href="validation.html#internal-validity-metrics"><i class="fa fa-check"></i><b>23.1</b> Internal Validity Metrics</a>
<ul>
<li class="chapter" data-level="23.1.1" data-path="validation.html"><a href="validation.html#common-measures-of-cohesion-and-separation"><i class="fa fa-check"></i><b>23.1.1</b> Common Measures of Cohesion and Separation</a></li>
</ul></li>
<li class="chapter" data-level="23.2" data-path="validation.html"><a href="validation.html#external"><i class="fa fa-check"></i><b>23.2</b> External Validity Metrics</a>
<ul>
<li class="chapter" data-level="23.2.1" data-path="validation.html"><a href="validation.html#accuracy"><i class="fa fa-check"></i><b>23.2.1</b> Accuracy</a></li>
<li class="chapter" data-level="23.2.2" data-path="validation.html"><a href="validation.html#entropy"><i class="fa fa-check"></i><b>23.2.2</b> Entropy</a></li>
<li class="chapter" data-level="23.2.3" data-path="validation.html"><a href="validation.html#purity"><i class="fa fa-check"></i><b>23.2.3</b> Purity</a></li>
<li class="chapter" data-level="23.2.4" data-path="validation.html"><a href="validation.html#mutual-information-mi-and-normalized-mutual-information-nmi"><i class="fa fa-check"></i><b>23.2.4</b> Mutual Information (MI) and <br> Normalized Mutual Information (NMI)</a></li>
<li class="chapter" data-level="23.2.5" data-path="validation.html"><a href="validation.html#other-external-measures-of-validity"><i class="fa fa-check"></i><b>23.2.5</b> Other External Measures of Validity</a></li>
<li class="chapter" data-level="23.2.6" data-path="validation.html"><a href="validation.html#summary-table"><i class="fa fa-check"></i><b>23.2.6</b> Summary Table</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="24" data-path="findk.html"><a href="findk.html"><i class="fa fa-check"></i><b>24</b> Determining the Number of Clusters <span class="math inline">\(k\)</span></a>
<ul>
<li class="chapter" data-level="24.1" data-path="findk.html"><a href="findk.html#methods-based-on-cluster-validity-stopping-rules"><i class="fa fa-check"></i><b>24.1</b> Methods based on Cluster Validity (Stopping Rules)</a></li>
<li class="chapter" data-level="24.2" data-path="findk.html"><a href="findk.html#sum-squared-error-sse-cohesion-plots"><i class="fa fa-check"></i><b>24.2</b> Sum Squared Error (SSE) Cohesion Plots</a>
<ul>
<li class="chapter" data-level="24.2.1" data-path="findk.html"><a href="findk.html#cosine-cohesion-plots-for-text-data"><i class="fa fa-check"></i><b>24.2.1</b> Cosine-Cohesion Plots for Text Data</a></li>
<li class="chapter" data-level="24.2.2" data-path="findk.html"><a href="findk.html#ray-and-turis-method"><i class="fa fa-check"></i><b>24.2.2</b> Ray and Turi’s Method</a></li>
<li class="chapter" data-level="24.2.3" data-path="findk.html"><a href="findk.html#the-gap-statistic"><i class="fa fa-check"></i><b>24.2.3</b> The Gap Statistic</a></li>
</ul></li>
<li class="chapter" data-level="24.3" data-path="findk.html"><a href="findk.html#perroncluster"><i class="fa fa-check"></i><b>24.3</b> Graph Methods Based on Eigenvalues <br> (Perron Cluster Analysis)</a></li>
</ul></li>
<li class="chapter" data-level="25" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i><b>25</b> References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Linear Algebra for Data Science</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="intro" class="section level1" number="1">
<h1><span class="header-section-number">Chapter 1</span> Introduction</h1>
<div id="what-is-linear-algebra" class="section level2" number="1.1">
<h2><span class="header-section-number">1.1</span> What is Linear Algebra?</h2>
<p>At its heart, Linear Algebra is the study of <strong>linear functions</strong>. The term <strong>linear</strong> should be understood to mean <em>straight</em> or <em>flat</em>. A line on the two dimensional coordinate plane, written <span class="math display">\[y=mx+b\]</span> represents a linear equation - the set of points <span class="math inline">\((x,y)\)</span> satisfying this equation form a straight line. On the other hand, a quadratic equation like <span class="math display">\[y=ax^2+bx+c\]</span> is <em>nonlinear</em> - it is not straight, it has curvature. You may have learned that the equation of a plane in 3-dimensional space (the coordinate cube <span class="math inline">\((x,y,z)\)</span>) is written as
<span class="math display">\[ax+by+cz=d.\]</span>
Such a plane is a classic example - the set of points <span class="math inline">\((x,y,z)\)</span> satisfying this equation form a flat surface (a plane).</p>
<p>A linear function involves only multiplication by scalars and addition/subtraction, for example:
<span class="math display">\[2x+3y+6z=9 \quad \mbox{or} \quad 4x_1-3x_2+9x_3+x_4-x_5+2x_6 = 2.\]</span>
The second equation above brings us to an important point: we don’t have to restrict ourselves to a 3-dimensional world. While the “flatness” of linear equations is evident when we can graph them in 2 and 3-dimensions, with 6 variables we can no longer conceptualize the “flatness” of our equation. We take on principal that the surface that contains all solutions to the equation <span class="math inline">\(4x_1-3x_2+9x_3+x_4-x_5+2x_6 = 2\)</span> is flat, without curvature, existing in a 6-dimensional space (or higher!). You may be asking now: <em>what is 6-dimensional space?</em> We’ll get to the the definition of <span class="math inline">\(n\)</span>-space soon (Definition <a href="intro.html#def:nspace">1.5</a>), but it should satisfy your intuition to extend your basic notion of coordinate axes. If you have 3 variables of interest, say <em>height</em>, <em>weight</em> and <em>circumference</em>, you can make a 3-d scatter plot because we have 3 physical dimensions to map to each characteristic. Add in a forth variable, say <em>cost</em>, and suddenly we cannot <em>physically</em> consider the plot (because our perception is limited to 3-dimensions) but we ought to be able to suspend our disbelief and assume that a “forth axes” (forth dimension) can be considered to represent cost.</p>
<p>In some cases, this course will challenge you to think geometrically about data. Not in terms of the geometry you learned in high school regarding polygons and circles, but in terms of the layout and patterns of data. Linear algebra allows us to develop concepts of distance and similarity when our data has more than 3 variables and we can no longer look at a scatter plot and use our eyeballs to declare “these two observations are far away from each other.”</p>
<p>The second term in the phrase is, of course, <strong>algebra.</strong> While you are likely familiar with the term, this course will challenge your initial familiarity. Linear Algebra deals with the algebra of matrices, which is likely different from any algebra you’ve experienced before. For example, when given an equation for an unknown value, like
<span class="math display">\[2x=3,\]</span> you probably immediately think “I should divide both sides by 2 to determine the unknown value x.” Our equations in this course will be quite different because the expressions will involve matrices and vectors. For example,
<span class="math display">\[\left(\begin{matrix} 2 &amp; 3\\1&amp;4 \end{matrix}\right) \left(\begin{matrix} x_1\\x_2 \end{matrix}\right) = \left(\begin{matrix} 5\\6 \end{matrix}\right)\]</span>
is one type of equation we will learn to solve in this course. In this situation, we cannot simply divide both sides by the left hand matrix to solve for the unknowns - in fact it should look quite confusing to consider what that would even mean!</p>
<p>Learning to work with matrices will be like learning a new language - the only way to succeed will be to practice and struggle and practice and struggle. Keep pace with the course and learn the terminology and definitions foremost - without the language and notation firmly in place, the techniques will seem far more difficult than they actually are.</p>
</div>
<div id="why-linear-algebra" class="section level2" number="1.2">
<h2><span class="header-section-number">1.2</span> Why Linear Algebra</h2>
<p>If you want to understand the foundations of data science, it is imperative that you be familiar with Linear Algebra. As you’ve probably already noticed, data tends to come in rows and columns. By its very nature, data forms a matrix. A <strong>matrix</strong> is just an array of numbers, logically ordered by rows and columns. For example take the following data:</p>
<p>To do anything to this data, we need a way to store it mathematically. This is done by creating a matrix:</p>
<p>The rows of this matrix correspond to observations, in this case a sample of people for whom we have collected data. The columns of this matrix correspond to the variables we are measuring. Some manipulation and pre-processing is usually required to turn nominal/categorical/qualitative variables into numerical data, often using binary dummy variables. Most every tool in data science involves some form of linear algebra on a data matrix. In this course, we will learn some of the foundations of these tools. If you master the material in this course, you will be able to understand many more advanced data techniques as you progress through your careers. With that in mind, let’s start at the beginning.</p>
</div>
<div id="describing-matrices-and-vectors" class="section level2" number="1.3">
<h2><span class="header-section-number">1.3</span> Describing Matrices and Vectors</h2>
<p>As we alluded to earlier, <strong>matrices</strong> are simply arrays of numbers which correspond in some way to their rows and columns. The following are examples of matrices:
<span class="math display">\[\A=\left(\begin{matrix} 1 &amp; 2\\3&amp;5 \end{matrix}\right) \qquad \mathbf{H}= \left(\begin{matrix} 6 &amp; 5&amp; 10\\0.1 &amp; 0.5 &amp; 0.9\\1&amp;4&amp;1\\1&amp;1&amp;1\\2&amp;0.4&amp;9.99 \end{matrix}\right)\]</span></p>
<p>In this text, when we denote a matrix, we will always use a bold capital letter like <span class="math inline">\(\mathbf{A}, \mathbf{M}, \mbox{or } \mathbf{D}\)</span>. To start, lets cover some basic properties and notation.</p>
<div id="dimensionsize-of-a-matrix" class="section level3" number="1.3.1">
<h3><span class="header-section-number">1.3.1</span> Dimension/Size of a Matrix</h3>
<div class="definition">
<p><span id="def:dim" class="definition"><strong>Definition 1.1  (Dimension/Size of a Matrix) </strong></span>The <strong>dimension</strong> of a matrix is the number of rows and number of columns in the matrix. This is sometimes referred to as the <strong>size</strong> of the matrix. We say a matrix in <span class="math inline">\(m\times n\)</span> if it has <span class="math inline">\(m\)</span> rows and <span class="math inline">\(n\)</span> columns. If <span class="math inline">\(\A\)</span> is a matrix, we might specify the dimensions of <span class="math inline">\(\A\)</span> with a subscript: <span class="math inline">\(\A_{m\times n}\)</span> should be read <em><span class="math inline">\(\A\)</span> is an <span class="math inline">\(m\times n\)</span> matrix</em>.</p>
<p>An <span class="math inline">\(n\times n\)</span> matrix is called a <strong>square matrix</strong> because it has the same number of rows and columns. A matrix without this characteristic is called a <strong>rectangular matrix.</strong></p>
</div>
<div class="example">
<p><span id="exm:dimensions" class="example"><strong>Example 1.1  (Dimensions of a Matrix) </strong></span>Consider the data matrix presented previously, containing observations on the two variables <em>Credit Score</em> and <em>Income</em>:</p>
<p><span class="math display">\[
\A\,=\left(\begin{matrix}
780 &amp; 95000\cr
600 &amp; 60000\cr
550 &amp; 65000\cr
400 &amp; 35000\cr
450 &amp; 40000\cr
750 &amp; 80000\end{matrix}\right)
\]</span></p>
<p>The dimension of the matrix <span class="math inline">\(\A\)</span> is <span class="math inline">\(6\times 2\)</span> because <span class="math inline">\(\A\)</span> has 6 rows and 2 columns. Thus when referring to <span class="math inline">\(\A\)</span> we might write <span class="math inline">\(\A_{6\times 2}\)</span> when the size is important. Note that the number of rows <em>always</em> comes first when specifying the size of a matrix!</p>
</div>
<div class="exercise">
<p><span id="exr:dimensions" class="exercise"><strong>Exercise 1.1  (Determining dimension of a matrix) </strong></span>For the following matrices, determine the dimension:</p>
<p><span class="math display">\[\mathbf{B} = \left( \begin{matrix}1 &amp; 2 &amp; 0 \cr 2&amp;1&amp;0\cr3&amp;1&amp;1 \end{matrix}\right) \quad \mathbf{C} = \left(\begin{matrix} .01&amp;.5&amp;1.6&amp;1.7\\ .1&amp;3.5&amp;4&amp;2\\.61&amp;.55&amp;.46&amp;.17\cr1.2&amp;1.5&amp;1.6&amp;1\cr.31&amp;.35&amp;1.3&amp;2.3\\2.3&amp;3.5&amp;.06&amp;.7\\.3&amp;.2&amp;2.1&amp;1.8\end{matrix}\right) \quad \mathbf{T} = \left(\begin{matrix} 1\cr1.3\cr0.8\cr2\cr2.5\cr0.8\cr0.9 \end{matrix} \right)\]</span>
</p>
</div>
</div>
<div id="ij-notation" class="section level3" number="1.3.2">
<h3><span class="header-section-number">1.3.2</span> <span class="math inline">\((i,j)\)</span> Notation</h3>
<p>Now beyond just knowing how many rows and columns a matrix has, we frequently want to refer to a specific row or column that matrix. In Example <a href="intro.html#exm:dimensions">1.1</a> above, you may have noticed that the names of the individuals did not appear in our matrix - those names were merely <em>identifiers</em>. Of course we did not throw them away and erase them from our hard drive, we merely replaced them with an implied numerical index <span class="math inline">\(i=\{1,2,3,4,5,6\}\)</span> that corresponds to a row of the matrix for every person. As long as we don’t reorder the rows of our matrix, we will know that the correspondence is as follows:
<span class="math display">\[\left\lbrace \begin{array}{c}
row 1\\ row 2\\ row 3\\ row 4\\ row 5\\ row 6
\end{array}  \right\rbrace \Longleftrightarrow
\left\lbrace \begin{array}{c}
John\\ Sam\\ Elena\\ Jim\\ Eric\\ Helen
\end{array}  \right\rbrace\]</span></p>
<p>So, if I’d like to focus on data about <em>Eric</em> in particular, I’d have to look no further than the <span class="math inline">\(5^{th}\)</span> row of my matrix <span class="math inline">\(\A\)</span>. Similarly, if I want to know the <em>Credit Scores</em> of all individuals, I’d simply focus on the <span class="math inline">\(1^{st}\)</span> column of the matrix. Hence, to find <em>Eric’s Credit Score</em>, I’d aim my sight on the element of the matrix located in the <span class="math inline">\(5^{th}\)</span> row and <span class="math inline">\(1^{st}\)</span> column of the matrix <span class="math inline">\(\A\)</span>.</p>
<p>Now, rather than write an entire sentence each time we want to refer to an individual element or row, we will develop some notation. As a general rule, the letter <span class="math inline">\(i\)</span> is used to index the rows of a matrix and the letter <span class="math inline">\(j\)</span> is used to index the columns.</p>
<div class="definition">
<p><span id="def:ijnotdef" class="definition"><strong>Definition 1.2  (Notation for Elements of a Matrix) </strong></span>Two subscripts are used to identify individual elements of a matrix:</p>
<ul>
<li><p>The element of matrix <span class="math inline">\(\A\)</span> corresponding to <em>row</em> <span class="math inline">\(i\)</span> and <em>column</em> <span class="math inline">\(j\)</span> is written <span class="math inline">\(A_{ij}\)</span></p></li>
<li><p>The <strong>diagonal</strong> elements of a square matrix are those that have identical row and column indices: <span class="math inline">\(\A_{ii}\)</span></p></li>
</ul>
</div>
<p>Beyond these basic conventions, there are other common notational tricks that we will become familiar with. The first of these is writing a <strong>partitioned matrix</strong>. We will often want to consider a matrix as a collection of either rows or columns rather than individual elements. As we will see in the future, when we partition matrices in this form, we can view their multiplication in simplified form. This often leads us to a new view of the data which can be helpful for interpretation.</p>
<p>When we write <span class="math inline">\(\A=( \A_1 | \A_2 | \dots | \A_n )\)</span> we are viewing the matrix <span class="math inline">\(\A\)</span> as collection of column vectors, <span class="math inline">\(\A_i\)</span>, in the following way:
<span class="math display">\[\A=( \A_1 | \A_2 | \dots | \A_n )=\left(\begin{matrix} \uparrow &amp; \uparrow &amp;\uparrow&amp;\dots &amp; \uparrow \\
            \A_1&amp;\A_2&amp;\A_3&amp;\dots&amp;\A_p \\
            \downarrow &amp;\downarrow &amp;\downarrow &amp;\dots&amp;\downarrow   \end{matrix}\right) \]</span></p>
<p>Similarly, we can write <span class="math inline">\(\A\)</span> as a collection of row vectors:
<span class="math display">\[\A=\left(\begin{matrix} \A_1 \\ \A_2 \\ \vdots \\  \A_m \end{matrix}\right) = 
\left(\begin{matrix} \longleftarrow &amp; \A_1 &amp; \longrightarrow \\
 \longleftarrow &amp; \A_2 &amp; \longrightarrow \\
  \vdots &amp; \vdots &amp; \vdots \\
   \longleftarrow &amp; \A_m &amp; \longrightarrow \end{matrix}\right)\]</span></p>
<p>Sometimes, we will want to refer to both rows and columns in the same context. The above notation is not sufficient for this as we have <span class="math inline">\(\A_j\)</span> referring to either a column or a row. In these situations, we may use
<span class="math inline">\(\A_{\star j}\)</span> to reference the <span class="math inline">\(j^{th}\)</span> column and <span class="math inline">\(\A_{i \star}\)</span> to reference the <span class="math inline">\(i^{th}\)</span> row:</p>
<p><span class="math display">\[\bordermatrix{\blue{\acol{1}}&amp;\acol{2}&amp;\dots&amp;\dots &amp;\acol{n}}{~\\~\\~\\~\\~}{\pm \blue{a_{11}} &amp; a_{12} &amp;\dots &amp; \dots &amp; a_{1n} \\
\blue{\vdots} &amp; \vdots &amp;  &amp;  &amp; \vdots \\
\blue{a_{i1}} &amp; \dots&amp; a_{ij} &amp; \dots &amp; a_{in}\\
\blue{\vdots} &amp; \vdots &amp;  &amp;  &amp; \vdots \\
\blue{a_{m1}} &amp; \dots&amp; \dots &amp; \dots &amp; a_{mn} \mp}\]</span>
<span class="math display">\[\bordermatrix{&amp;&amp;&amp;&amp;&amp;}{\blue{\arow{1}} \\\vdots \\ \arow{i} \\ \vdots \\\arow{m}}{\pm  \blue{a_{11}} &amp; \blue{a_{12} }&amp;\blue{\dots} &amp; \blue{\dots} &amp; \blue{a_{1n}} \cr
 \vdots&amp; \vdots &amp;  &amp;  &amp; \vdots \cr
 a_{i1} &amp; \dots&amp; a_{ij} &amp; \dots &amp; a_{in}\cr
 \vdots &amp; \vdots &amp;  &amp;  &amp; \vdots \cr
  a_{m1} &amp; \dots&amp; \dots &amp; \dots &amp; a_{mn} \mp}\]</span></p>
<div class="definition">
<p><span id="def:rowcol" class="definition"><strong>Definition 1.3  (Rows and Columns of a Matrix) </strong></span>To refer to entire rows or columns, a placeholder <span class="math inline">\(\star\)</span> is often used to represent the idea that we take <em>all</em> rows or columns after narrowing in on a given column or row respectively:</p>
<ul>
<li><p>To refer to the <span class="math inline">\(k^{th}\)</span> row of <span class="math inline">\(\A\)</span> we will use the notation <span class="math inline">\(\arow{k}\)</span> (“$k^{th} row, <em>all</em> columns”)<br />
</p></li>
<li><p>Similarly, to refer to the <span class="math inline">\(k^{th}\)</span> column of <span class="math inline">\(\A\)</span> we will use the notation <span class="math inline">\(\acol{k}\)</span>.<br />
</p></li>
</ul>
<p>Often, when there is no confusion about whether we are referring to rows or columns, the above notation will be shortened to simply <span class="math inline">\(\A_k\)</span>. In such a scenario it will be made clear from context whether this represents the <span class="math inline">\(k^{th}\)</span> row or <span class="math inline">\(k^{th}\)</span> column. For example,
<span class="math display">\[\A=( \A_1 | \A_2 | \dots | \A_n )\]</span>
represents a matrix <span class="math inline">\(\A\)</span> with <span class="math inline">\(n\)</span> columns <span class="math inline">\(\{\A_1,\A_2,\dots,\A_n\}\)</span>.</p>
</div>
<p>:::{.example name=‘Rows, Columns, and Elements of a Matrix’ #ijnot}</p>
Consider the following table of data and corresponding data matrix:
<table>
<tr>
<td>
Obs.
<td>
Height (in.)
<td>
Weight (lbs.)
<td>
Age
<tr>
<td>
1
<td>
63
<td>
120
<td>
23
<tr>
<td>
2
<td>
69
<td>
170
<td>
30
<tr>
<td>
3
<td>
72
<td>
190
<td>
41
<tr>
<td>
4
<td>
64
<td>
150
<td>
27
<tr>
<td>
5
<td>
64
<td>
175
<td>
35
<tr>
<td>
6
<td>
68
<td>
165
<td>
25
<tr>
<td>
7
<td>
70
<td>
180
<td>
21
</td>
</tr>
</table>
<p><span class="math display">\[\mathbf{B}=
\left(\begin{matrix}63 &amp; 120 &amp; 23\\
69 &amp; 170 &amp; 30\\
72 &amp; 190 &amp; 41\\
64 &amp; 150 &amp; 27\\
64 &amp; 175 &amp; 35\\
68 &amp; 165 &amp; 25\\
70 &amp; 180 &amp; 21\end{matrix}\right)\]</span></p>
<p>Element <span class="math inline">\(B_{42}=150\)</span> corresponds to the <em>weight</em> (second column) of <em>observation 4</em> (forth row).</p>
<p>The column <span class="math display">\[\bcol{3} = \left(\begin{matrix} 23\\30\\41\\27\\35\\25\\21 \end{matrix}\right)\]</span> corresponds to the variable <em>age</em> and the row <span class="math display">\[\brow{6} = \left(\begin{matrix} 68&amp;165&amp;25 \end{matrix}\right)\]</span> corresponds to the measurements for <em>observation 6</em>.
:::</p>
<div class="exercise">
<p><span id="exr:ijnot" class="exercise"><strong>Exercise 1.2  (Rows, Columns, and Elements of a Matrix) </strong></span>For the matrix
<span class="math display">\[ \mathbf{L}=\left(\begin{matrix} 3 &amp; -6 &amp; -2\\1 &amp; -4 &amp; 5\\0 &amp; 4 &amp; -5 \end{matrix}\right)\]</span>
Write the following elements, rows, or columns:

<span class="math display">\[L_{23}= \qquad\qquad L_{31}= \qquad\qquad \mathbf{L}_{\star 2}= \qquad\qquad \mathbf{L}_{1 \star}=\qquad\qquad\]</span>
</p>
</div>
<div class="definition">
<p><span id="def:equality" class="definition"><strong>Definition 1.4  (Equality of Matrices) </strong></span>Two matrices are <strong>equal</strong> if and only if they have the same size and all of their corresponding entries are equal. That is,
<span class="math display">\[\A=\B \Longleftrightarrow A_{ij} = B_{ij} \quad \mbox{for all i and j}\]</span></p>
</div>
</div>
<div id="example-defining-social-networks" class="section level3 unnumbered">
<h3>Example: Defining social networks</h3>
<p>One advantage to using (i,j)-notation is that it allows us to define an entire matrix by describing one arbitrary element according to its row (<span class="math inline">\(i\)</span>) and column (<span class="math inline">\(j\)</span>). Let’s consider a classic example from network analysis. Suppose we have a group of 6 students and we want to examine how often they have worked together in teams. Rather than use the students names, let’s just number them Student 1 through Student 6. These students were put into teams in the summer semester and then reassigned to new teams for the fall and the spring semester:</p>
<p>Now, we can define what is called an <em>adjacency</em> or <em>association</em> matrix for this data as follows:</p>
<p><span class="math display">\[\A_{ij} =\left\{ \begin{array}{l}
\mbox{# of times Student i has worked with Student j}\,\,\,\mbox{if } i\neq j\\
0 \,\,\,\mbox{ if } i=j 
\end{array} \right.\]</span></p>
<p>Breaking apart this matrix definition, we see both the rows (indexed by <span class="math inline">\(i\)</span>) and columns (indexed by <span class="math inline">\(j\)</span>) will correspond to students. For example, the element in the <span class="math inline">\(2^{nd}\)</span> row and <span class="math inline">\(3^{rd}\)</span> column, (<span class="math inline">\(A_{23}\)</span>), will be the number of times Student 2 has worked with Student 3. Thus,
<span class="math display">\[A_{23}=2.\]</span>
When the row and column numbers are the same (<span class="math inline">\(i=j\)</span>), which happens along the <em>diagonal</em> of the matrix, the entries will be 0 (this number was chosen arbitrarily - one could also use `3’ along the diagonal). The result is a square matrix with 6 rows and columns:
<span class="math display">\[\A=\left(\begin{matrix} 0&amp;2&amp;1&amp;1&amp;1&amp;1\\2&amp;0&amp;2&amp;2&amp;0&amp;0\\1&amp;2&amp;0&amp;1&amp;1&amp;1\\1&amp;2&amp;1&amp;0&amp;1&amp;1\\1&amp;0&amp;1&amp;1&amp;0&amp;3\\1&amp;0&amp;1&amp;1&amp;3&amp;0\end{matrix}\right)\]</span>
We can quickly see that there is symmetry in this matrix because the number of times Students <span class="math inline">\(i\)</span> and <span class="math inline">\(j\)</span> worked together is, of course, the same as the number of times Students <span class="math inline">\(j\)</span> and <span class="math inline">\(i\)</span> worked together. Formally, a matrix is called <strong>symmetric</strong> if <span class="math inline">\(A_{ij}=A_{ji}\)</span> (this important concept is formalized in Definition <a href="intro.html#def:symdef">1.7</a>. We can also see straight from this matrix that Students 5 and 6 worked together every semester while neither of them worked with Student 2 at all.</p>
<p>An adjacency matrix like the one listed above is often used to describe a <em>network</em> or <em>graph.</em> A <strong>graph</strong> is a collection of <strong>vertices</strong> (nodes) that each represent some entity, and <strong>edges</strong> which connect vertices that are related in some way.</p>
<p>Below is a network of the students, where the thickness of the edge between two vertices indicates the number of times they have worked together.</p>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-7"></span>
<img src="figs/studentgraph.jpg" alt="Network of Student Team Membership" width="50%" />
<p class="caption">
Figure 1.1: Network of Student Team Membership
</p>
</div>
<p>If we had chosen to put 3’s along the diagonal, each vertex in this graph would have a bold edge that loops back to itself. Graphs and the adjacency matrices which define them are at the heart of many problems in social network analysis. For example, websites like Facebook and LinkedIn are just enormous networks of nodes (individual users) connected by edges (“friendships” or “connections”). In the case of Twitter, the network is even more complicated because the relationships are <em>directed</em>: the “follower” connection is not symmetric, the people I “follow” do not have to follow me back. We may have a chance to discuss more of this later; in general, it makes the analysis much more difficult!</p>
</div>
<div id="introcorr" class="section level3" number="1.3.3">
<h3><span class="header-section-number">1.3.3</span> Example: Correlation matrices</h3>
<p>When we have several variables to analyze, it is good practice to measure the pairwise correlations between variables. Suppose we have 4 variables, <span class="math inline">\(x_1, x_2, x_3,\,\mbox{and}\, x_4\)</span>. We will often examine the <em>correlation matrix</em>, <span class="math inline">\(\C\)</span>, which is defined as follows:
<span class="math display">\[\C_{ij}=correlation(x_i,x_j).\]</span>
For example, suppose our correlation matrix is as follows:
<span class="math display">\[\C=\left(\begin{matrix} 1 &amp; 0.3 &amp; -0.9 &amp; 0.1\\0.3 &amp; 1 &amp; 0.8 &amp; -0.5\\-0.9&amp;0.8&amp;1&amp;-0.6\\0.1&amp;-0.5&amp;-0.6&amp;1 \end{matrix}\right)\]</span></p>
<p>It is clear that the diagonal elements of this matrix, <span class="math inline">\(C_{ii}\)</span>, should always equal 1 because every variable is perfectly correlated with itself. We can also see that</p>
<p><span class="math display">\[C_{ij}=C_{ji}\quad \mbox{Because }\,correlation(x_i,x_j)=correlation(x_j,x_i)\]</span>
And in this particular example,
<span class="math display">\[C_{13}=-0.9 \quad \mbox{Indicates that }\,x_1\,\,\mbox{and}\,\,x_3\,\,\mbox{have a strong negative correlation.}\]</span></p>
</div>
</div>
<div id="vectors" class="section level2" number="1.4">
<h2><span class="header-section-number">1.4</span> Vectors</h2>
<p>Now that we’ve introduced the concept of a matrix, let’s talk about vectors. A <strong>vector</strong> are merely a special type of matrix, one that consists of only a single row or column. They are essentially ordered lists of numbers. For example:</p>
<p><span class="math display">\[\x=\left(\begin{matrix} 5\\6\\7\\8 \end{matrix}\right) \qquad \mathbf{z}=\left(\begin{matrix} 3 &amp; 5 &amp; 1 &amp; 0 &amp; 2 \end{matrix}\right) \qquad \y = \left(\begin{matrix} y_1\\y_2\\y_3 \end{matrix}\right)\]</span>
are all examples of vectors; <span class="math inline">\(\x\)</span> and <span class="math inline">\(\y\)</span> are <strong>column vectors</strong> and <span class="math inline">\(\mathbf{z}\)</span> is a <strong>row vector</strong>. In this text, to denote a vector we will always use a <em>bold lower-case letter</em> like <span class="math inline">\(\x, \y, \mbox{or } \mathbf{a}\)</span>. Since vectors only have one row or column, we do not need two subscripts to refer to their elements - we can use a single subscript to refer to the elements, as shown in the vector <span class="math inline">\(\y\)</span>. Thus, <span class="math inline">\(x_3\)</span> refers to the <span class="math inline">\(3^{rd}\)</span> element in the vector <span class="math inline">\(\x\)</span> above: <span class="math display">\[x_3 = 7.\]</span> Notice that the elements of a vector are not written in bold. In fact, all <strong>scalar</strong> quantities (a quantity that is just a single number (like 2 or <span class="math inline">\(\sqrt{5}\)</span>), not a matrix) will be represented by unbolded, usually lowercase (often greek) letters. For example, letters like <span class="math inline">\(\alpha, \beta, x_i, \mbox{or } a\)</span> will be used to refer to scalars.</p>
<p>You may wonder now why the notation is so particular, but as we get into the subject it will be come clear that some convention must be retained if we are going to understand an equation. If we write an equation like
<span class="math display">\[\A\x=\b \qquad \mbox{or} \qquad \mathbf{M}\y=\alpha\y\]</span>
We have to know what it represents - in the first case, we are dealing with a matrix <span class="math inline">\(\A\)</span>, and two vectors <span class="math inline">\(\x\)</span> and <span class="math inline">\(\b\)</span>; in the second case we are dealing with a matrix <span class="math inline">\(\mathbf{M}\)</span>, a vector <span class="math inline">\(\y\)</span>, and a scalar, <span class="math inline">\(\alpha\)</span>.</p>
<div class="exercise">
<p><span id="exr:matnot" class="exercise"><strong>Exercise 1.3  (Matrix, Vector, and Scalar Notation) </strong></span>For the following quantities, indicate whether the notation indicates a Matrix, Scalar, or Vector.

<span class="math display">\[\A \qquad \qquad A_{ij} \qquad \qquad \v \qquad \qquad  p_2 \qquad \qquad  \lambda  \qquad \qquad \p_2\]</span>
</p>
</div>
<p>In the previous exercise, we see an important difference: <span class="math inline">\(p_2\)</span> is not bold, and thus is automatically assumed to a scalar, while <span class="math inline">\(\p_2\)</span> is bold and lowercase meaning, despite the subscript, it refers to a vector.</p>
<div id="vector-geometry-n-space" class="section level3" number="1.4.1">
<h3><span class="header-section-number">1.4.1</span> Vector Geometry: <span class="math inline">\(n\)</span>-space</h3>
<p>You are already familiar with the concept of “ordered pairs” or coordinates <span class="math inline">\((x_1,x_2)\)</span> on the two-dimensional plane (in Linear Algebra, we call this plane “<span class="math inline">\(2\)</span>-space”). Fortunately, we do not live in a two-dimensional world! Our data will more often consist of measurements on a number (lets call that number <span class="math inline">\(n\)</span>) of variables. Thus, our data points belong to what is known as <span class="math inline">\(n\)</span>-space. They are represented by <strong><span class="math inline">\(n\)</span>-tuples</strong> which are nothing more than ordered lists of numbers:
<span class="math display">\[(x_1, x_2, x_3, \dots, x_n).\]</span>
An <span class="math inline">\(n\)</span>-tuple defines a <strong>vector</strong> with the same <span class="math inline">\(n\)</span> elements, and so these two concepts should be thought of interchangeably. The only difference is that the vector has a direction (usually depicted with an arrow), away from the origin and toward the <span class="math inline">\(n\)</span>-tuple. This concept is obviously very difficult to visualize when <span class="math inline">\(n&gt;3\)</span>, but our mental visualizations of <span class="math inline">\(2-\)</span> and <span class="math inline">\(3-\)</span>space will usually be sufficient when we want to consider higher dimensional spaces.</p>
<div class="example">
<span id="exm:twospace" class="example"><strong>Example 1.2  (2-space) </strong></span>Whereas we once thought of ordered pairs as <em>points</em> in space, we can also consider the coordinates as defining <em>vectors</em>. In almost every scenario, these two concepts can be thought of equivalently, however the direction of vectors helps us define their arithmetic geometrically, as we will see in the next chapter.
<center>
<img src="figs/2spacePoints.pdf" width=300 />
<img src="figs/2space.pdf" width=300 />
</center>
</div>
<p>You will recall that the symbol <span class="math inline">\(\Re\)</span> is used to denote the set of real numbers. <span class="math inline">\(\Re\)</span> is simply <span class="math inline">\(1\)</span>-space. It is a set of vectors with a single element. In this sense any real number, <span class="math inline">\(x\)</span>, has a direction: if it is positive, it is to one side of the origin, if it is negative it is to the opposite side. That number, <span class="math inline">\(x\)</span>, also has a magnitude: <span class="math inline">\(|x|\)</span> is the distance between <span class="math inline">\(x\)</span> and the origin, 0.</p>
<div class="definition">
<p><span id="def:nspace" class="definition"><strong>Definition 1.5  (n-space) </strong></span><span class="math inline">\(n\)</span>-space (the set of real <span class="math inline">\(n\)</span>-tuples) is denoted <span class="math inline">\(\Re^n\)</span>. In set notation, the formal mathematical definition is simply:
<span class="math display">\[\Re^n = \left\lbrace (x_1,x_2,\dots,x_n) : x_i \in \Re, i=1,\dots, n\right\rbrace.\]</span></p>
</div>
<p>We will often use this notation to define the size of an arbitrary vector. For example, <span class="math inline">\(\x \in \Re^p\)</span> simply means that <span class="math inline">\(\x\)</span> is a vector with <span class="math inline">\(p\)</span> entries:
<span class="math inline">\(\x=(x_1,x_2,\dots,x_p)\)</span>.</p>
<p>Many (all, really) of the concepts we have previously considered in <span class="math inline">\(2\)</span>- or <span class="math inline">\(3\)</span>-space extend naturally to <span class="math inline">\(n\)</span>-space and a few new concepts become useful as well. One very important concept is that of a <strong>norm</strong> or distance metric, as we will see in Chapter <a href="norms.html#norms">6</a>. Before we get into the details of the vector space model, let’s continue with some of the basic definitions we will need on that journey.</p>
</div>
</div>
<div id="matrix-operations" class="section level2" number="1.5">
<h2><span class="header-section-number">1.5</span> Matrix Operations</h2>
<div id="transpose" class="section level3" number="1.5.1">
<h3><span class="header-section-number">1.5.1</span> Transpose</h3>
<p>One important transformation we will have to perform on a matrix is to switch the columns into rows. It is not necessary that you see the importance of this transformation right now, but trust that it is something we will need quite frequently.</p>
<div class="definition">
<p><span id="def:transposedef" class="definition"><strong>Definition 1.6  (Transpose of a Matrix or Vector) </strong></span>For a given <span class="math inline">\(m\times n\)</span> matrix <span class="math inline">\(\A\)</span>, the <strong>transpose</strong> of <span class="math inline">\(\A\)</span>, written <span class="math inline">\(\A^T\)</span> (read as “<span class="math inline">\(\A\)</span>-transpose”) in this course and sometimes elsewhere denoted as <span class="math inline">\(\A&#39;\)</span> is the <span class="math inline">\(n\times m\)</span> matrix whose rows are the corresponding columns of <span class="math inline">\(\A\)</span>.</p>
<p>Thus, if <span class="math inline">\(\A\)</span> is a <span class="math inline">\(3\times 4\)</span> matrix then <span class="math inline">\(\A^T\)</span> is a <span class="math inline">\(4\times 3\)</span> matrix as follows:
<span class="math display">\[\A = \left(\begin{matrix} A_{11} &amp; A_{12} &amp; A_{13} &amp;A_{14}\\ A_{21} &amp; A_{22} &amp; A_{23} &amp;A_{24}\\ A_{31} &amp; A_{32} &amp; A_{33} &amp;A_{34}\end{matrix}\right)
\quad  \A^T = \left(\begin{matrix} A_{11} &amp; A_{21} &amp; A_{31}\\A_{12} &amp; A_{22} &amp; A_{32}\\A_{13} &amp; A_{23} &amp; A_{33}\\A_{14} &amp; A_{24} &amp; A_{34}\end{matrix}\right)\]</span></p>
<p>An equivalent way to state this definition is to say that
<span class="math display">\[(A^T)_{ij} = A_{ji}\]</span>
<em>Note: If we transpose the transpose of a matrix, we will get back the original matrix. That is,</em> <span class="math display">\[(\A^T)^T = \A.\]</span></p>
</div>
<div class="example">
<p><span id="exm:transpose" class="example"><strong>Example 1.3  (Transpose of a Matrix or Vector) </strong></span>For the following matrices and vectors, determine the transpose:
<span class="math display">\[\B=\left(\begin{matrix} 2 &amp; -3 &amp; -4 \\5&amp;-6&amp;-7\\-8&amp;9&amp;0 \end{matrix}\right) \qquad \mathbf{M}=\left(\begin{matrix} -1&amp;2\\-3&amp;6\\7&amp;-9\\5&amp;-1 \end{matrix}\right) \qquad \x=\left(\begin{matrix}3\\-4\\5\\6\end{matrix}\right)\]</span>
To find the transpose, we simply create new matrices whose rows are the corresponding columns of each matrix or vector:
<span class="math display">\[\B^T=\left(\begin{matrix} 2 &amp;5&amp; -8\\-3&amp;-6&amp;9\\-4&amp;-7&amp;0\end{matrix}\right) \qquad \mathbf{M}^T = \left(\begin{matrix}-1&amp;-3&amp;7&amp;5\\2&amp;6&amp;-9&amp;-1 \end{matrix}\right) \]</span> <span class="math display">\[\x^T = \left(\begin{matrix} 3&amp;-4&amp;5&amp;6 \end{matrix}\right)\]</span></p>
</div>
<div class="definition">
<p><span id="def:symdef" class="definition"><strong>Definition 1.7  (Symmetric Matrix) </strong></span>Defining the matrix transpose allows us to define the notion of a <em>symmetric matrix</em>. A matrix <span class="math inline">\(\A\)</span> is called <strong>symmetric</strong> if and only if <span class="math display">\[\A=\A^T.\]</span>
This is equivalent to saying that <span class="math inline">\(\A\)</span> is symmetric if and only if
<span class="math display">\[A_{ij}=A_{ji}.\]</span>
It should be clear from the definition that in order for <span class="math inline">\(\A\)</span> to be a symmetric matrix, it <em>must</em> be a square matrix - otherwise <span class="math inline">\(\A\)</span> and <span class="math inline">\(\A^T\)</span> would not even have the same size!</p>
</div>
<div class="example">
<p><span id="exm:sym" class="example"><strong>Example 1.4  (Symmetric Matrices) </strong></span>The following matrix is symmetric because <span class="math inline">\(\B^T = \B\)</span>.
<span class="math display">\[\B=\left(\begin{matrix} 2 &amp; 0 &amp; 1 \\0&amp;-6&amp;-7\\1&amp;-7&amp;0 \end{matrix}\right)\]</span></p>
</div>
<div class="exercise">
<p><span id="exr:transposesym" class="exercise"><strong>Exercise 1.4  (Transpose and Symmetry) </strong></span>Given that,
<span class="math display">\[\A=\left(\begin{matrix} 2 &amp; -4 \\-1&amp;2\\3&amp;-6 \end{matrix}\right) \quad \v^T = \left(\begin{matrix} 1 &amp; 0 &amp; -2 &amp; 5\end{matrix}\right) \quad \B=\left(\begin{matrix} B_{11}&amp;B_{12}&amp;B_{13}\\B_{21}&amp;B_{22}&amp;B_{23}\\B_{31}&amp;B_{32}&amp;B_{33}\\B_{41}&amp;B_{42}&amp;B_{43}\end{matrix}\right)\]</span>
compute the following matrices:

<span class="math display">\[\A^T= \qquad \qquad \qquad \qquad (\A^T)^T= \qquad \qquad \qquad \qquad\]</span>

<span class="math display">\[ \v= \qquad \qquad \qquad \qquad \B^T = \qquad \qquad\qquad \qquad \]</span>
</p>
<p>Give an example of a <span class="math inline">\(4\times 4\)</span> symmetric matrix:<br />
</p>
<p>Is a correlation matrix symmetric? (For a hint, see section <a href="intro.html#introcorr">1.3.3</a>)<br />
</p>
</div>
</div>
<div id="trace-of-a-matrix" class="section level3" number="1.5.2">
<h3><span class="header-section-number">1.5.2</span> Trace of a Matrix</h3>
<p>Another important matrix operation that will come into play later is the <em>trace</em> of a matrix. The <strong>trace</strong> of a square matrix is the sum of the diagonal elements of this matrix.</p>
<div class="definition">
<p><span id="def:tracedef" class="definition"><strong>Definition 1.8  (Trace of a Matrix) </strong></span>For an <span class="math inline">\(n\times n\)</span> square matrix, <span class="math inline">\(\A\)</span>, the <strong>trace</strong> of <span class="math inline">\(\A\)</span>, written
<span class="math display">\[trace(\A)\,\,\,\mbox{or}\,\,\,tr(\A)\]</span>
is the sum of the diagonal elements:
<span class="math display">\[tr(\A)=\sum_{i=1}^n A_{ii}\]</span></p>
<p>The trace of a rectangular matrix is undefined.</p>
</div>
<div class="example">
<p><span id="exm:trace" class="example"><strong>Example 1.5  (Trace of a Matrix) </strong></span>Let <span class="math display">\[\A=\left(\begin{matrix} 3&amp;4&amp;1\\0&amp;1&amp;-2\\-1&amp;\sqrt{2}&amp;3\end{matrix}\right)\]</span>
Then, the trace of <span class="math inline">\(\A\)</span> is the sum of the diagonal elements:
<span class="math display">\[tr(\A)=\sum_{i=1}^3 A_{ii} = 3+1+3 = 7.\]</span></p>
</div>
<p>While we’re on the subject of diagonal elements, let’s take the opportunity to introduce some special types of matrices, namely the <strong>identity matrix</strong> and a <strong>diagonal matrix</strong>.</p>
</div>
</div>
<div id="special" class="section level2" number="1.6">
<h2><span class="header-section-number">1.6</span> Special Matrices and Vectors</h2>
<div class="definition">
<p><span id="def:identity" class="definition"><strong>Definition 1.9  (Identity Matrix) </strong></span>The bold capital letter <span class="math inline">\(\mathbf{I}\)</span> will always to denote the <strong>identity matrix</strong>. Sometimes this matrix has a single subscript to specify the size of the matrix. More often, the size of the identity is implied by the matrix equation in which it appears.
<span class="math display">\[\mathbf{I}_4 = \left(\begin{matrix} 1 &amp; 0 &amp; 0 &amp; 0 \\
                        0 &amp; 1 &amp; 0 &amp; 0\\
                        0&amp;0&amp;1&amp;0\\
                        0&amp;0&amp;0&amp;1 \end{matrix}\right)\]</span></p>
</div>
<div class="definition">
<p><span id="def:elemvectors" class="definition"><strong>Definition 1.10  (Elementary Vectors) </strong></span>The bold lowercase <span class="math inline">\(\mathbf{e}_j\)</span> is used to refer to the <span class="math inline">\(j^{th}\)</span> column of <span class="math inline">\(\mathbf{I}\)</span>. It is simply a vector of zeros with a one in the <span class="math inline">\(j^{th}\)</span> position. We do not often specify the size of the vector <span class="math inline">\(\mathbf{e}_j\)</span>, the number of elements is generally assumed from the context of the problem.</p>
<p><span class="math display">\[\mathbf{e}_j=\begin{matrix}
\begin{matrix} ~ \\~\\~\\~\\j^{th}\text{row} \rightarrow \\ ~\\~\\~ \end{matrix} &amp; 
  \begin{pmatrix}0\\0\\ \vdots \\0\\1\\0\\ \vdots\\0\end{pmatrix}\\\\
\end{matrix}\]</span></p>
<p>The vector <span class="math inline">\(\mathbf{e}\)</span> with no subscript refers to a vector of all ones. In some texts, this vector is written as a bold faced <span class="math inline">\(\textbf{1}\)</span>.</p>
<p><span class="math display">\[\mathbf{e} = \left(\begin{matrix} 1\\1\\1\\ \vdots \\ 1\end{matrix}\right)\]</span></p>
</div>
<p>The elementary vectors described in Definition <a href="intro.html#def:elemvectors">1.10</a> create the coordinate axes of <span class="math inline">\(n\)</span>-space. For illustrative purposes, let’s consider <span class="math inline">\(2\)</span>-space. The elementary vectors in <span class="math inline">\(2\)</span>-space are:
<span class="math display">\[\e_1 = \left(\begin{matrix} 1\\0\end{matrix}\right) \quad \mbox{and} \quad \e_2 = \left(\begin{matrix} 0\\1 \end{matrix}\right) \]</span>
These vectors correspond to the directions of the coordinate axes as illustrated in Figure <a href="intro.html#fig:elemvectors">1.2</a></p>
<div class="figure" style="text-align: center"><span id="fig:elemvectors"></span>
<img src="figs/elemvectors.jpg" alt="Elementary cectors represent our &quot;usual&quot; coordinate axes" width="50%" />
<p class="caption">
Figure 1.2: Elementary cectors represent our “usual” coordinate axes
</p>
</div>
<div class="definition">
<p><span id="def:diag" class="definition"><strong>Definition 1.11  (Diagonal Matrix) </strong></span>A <strong>diagonal matrix</strong> is a matrix for which off-diagonal elements, <span class="math inline">\(\A_{ij},\,i\ne j\)</span> are zero.
For example:
<span class="math display">\[\mathbf{D} = \left(\begin{matrix} \sigma_1 &amp; 0 &amp; 0 &amp; 0 \\
                        0 &amp; \sigma_2 &amp; 0 &amp; 0\\
                        0&amp;0&amp;\sigma_3&amp;0\\
                        0&amp;0&amp;0&amp;\sigma_4 \end{matrix}\right)\]</span>
Since the off diagonal elements are 0, we need only define the diagonal elements for such a matrix. Thus, we will frequently write
<span class="math display">\[\mathbf{D}=diag\{\sigma_1,\sigma_2,\sigma_3,\sigma_4\}\]</span>
or simply <span class="math display">\[D_{ii} = \sigma_i.\]</span></p>
</div>
<p>From the preceding definitions, it should be clear that diagonal and identity matrices are always <em>square</em>, meaning they have the same number of rows and columns, and {symmetric}, meaning they do not change under the transpose operation.</p>
<div class="exercise">
<p><span id="exr:traceexer" class="exercise"><strong>Exercise 1.5  (Trace and Special Matrices) </strong></span>Write out the following matrices and then compute their Trace, if possible:</p>
<p><span class="math display">\[\I_5 \qquad \mathbf{D}=diag\{2,6,1\} \qquad \e_2 \in \Re^4\]</span>
</p>
</div>
<div class="definition">
<p><span id="def:triangulardef" class="definition"><strong>Definition 1.12  (Triangular Matrices) </strong></span>Triangular matrices are square matrices whose elements are zero either below or above the main diagonal. If the matrix has zeros below the main diagonal, then it’s called <strong>upper triangular</strong>. The following illustration depicts an upper triangular matrix, where the asterisk symbol is used to denote any number (including potential zeros).
<span class="math display">\[\left(\begin{matrix} *&amp;*&amp;*&amp;\dots&amp;*\\0&amp;*&amp;*&amp;\dots&amp;*\\0&amp;0&amp;*&amp;\dots&amp;*\\ \vdots &amp;\vdots &amp;\ddots &amp;\ddots&amp;*\\0&amp;0&amp;0&amp;0&amp;*\end{matrix}\right)\]</span></p>
<p>If a matrix has zeros above the main diagonal, then it’s called <strong>lower triangular</strong>. The following illustration depicts a lower triangular matrix.
<span class="math display">\[\left(\begin{matrix} 0&amp;0&amp;0&amp;\dots&amp;0\\ *&amp;0&amp;0&amp;\dots&amp;0\\ *&amp;*&amp;0&amp;\dots&amp;0\\ \vdots &amp;\vdots &amp;\ddots &amp;\ddots&amp;0\\ *&amp;*&amp;*&amp;*&amp;0\end{matrix}\right)\]</span></p>
</div>
<div class="exercise">
<p><span id="exr:triangularexer" class="exercise"><strong>Exercise 1.6  (Triangular Matrices) </strong></span>The following are examples of triangular matrices. Are they upper or lower triangular?</p>
<p><span class="math display">\[\left(\begin{matrix} 1&amp;2&amp;3&amp;4\\0&amp;5&amp;6&amp;7\\0&amp;0&amp;8&amp;9\\0&amp;0&amp;0&amp;1 \end{matrix}\right) \quad \left(\begin{matrix} -1&amp;0&amp;0\\0&amp;-2&amp;0\\1&amp;-1&amp;2 \end{matrix}\right) \quad \left(\begin{matrix} 0&amp;0&amp;0\\0&amp;0&amp;0\\0&amp;0&amp;0 \end{matrix}\right)\]</span></p>
</div>
</div>
<div id="summary-of-conventional-notation" class="section level2" number="1.7">
<h2><span class="header-section-number">1.7</span> Summary of Conventional Notation</h2>
<p>Linear Algebra has some conventional ways of representing certain types of numerical objects. Throughout this course, we will stick to the following basic conventions:</p>
<ul>
<li>Bold and uppercase letters like <span class="math inline">\(\A\)</span>, <span class="math inline">\(\X\)</span>, and <span class="math inline">\(\U\)</span> will be used to refer to matrices.</li>
<li>Occasionally, the size of the matrix will be specified by subscripts, like <span class="math inline">\(\A_{m\times n}\)</span>, which means that <span class="math inline">\(\A\)</span> is a matrix with <span class="math inline">\(m\)</span> rows and <span class="math inline">\(n\)</span> columns.</li>
<li>Bold and lowercase letters like <span class="math inline">\(\x\)</span> and <span class="math inline">\(\y\)</span> will be used to reference vectors. Unless otherwise specified, these vectors will be thought of as columns, with <span class="math inline">\(\x^T\)</span> and <span class="math inline">\(\y^T\)</span> referring to the row equivalent.</li>
<li>The individual elements of a vector or matrix will often be referred to with subscripts, so that <span class="math inline">\(A_{ij}\)</span> (or sometimes <span class="math inline">\(a_{ij}\)</span>) denotes the element in the <span class="math inline">\(i^{th}\)</span> row and <span class="math inline">\(j^{th}\)</span> column of the matrix <span class="math inline">\(\A\)</span>. Similarly, <span class="math inline">\(x_k\)</span> denotes the <span class="math inline">\(k^{th}\)</span> element of the vector <span class="math inline">\(\x\)</span>. These references to individual elements are not generally bolded because they refer to scalar quantities.</li>
<li>Scalar quantities are written as unbolded greek letters like <span class="math inline">\(\alpha\)</span>, <span class="math inline">\(\delta\)</span>, and <span class="math inline">\(\lambda\)</span>.</li>
<li>The notation <span class="math inline">\(\x \in \Re^n\)</span> simply means that <span class="math inline">\(\x\)</span> is a vector in <span class="math inline">\(n\)</span>-space, or a vector with <span class="math inline">\(n\)</span> elements.</li>
<li>The <strong>transpose</strong> of an <span class="math inline">\(m\times n\)</span> matrix <span class="math inline">\(\A\)</span> is the <span class="math inline">\(n\times m\)</span> matrix <span class="math inline">\(\A^T\)</span> whose rows are the columns of <span class="math inline">\(\A\)</span>.</li>
<li>The <strong>trace</strong> of a square matrix <span class="math inline">\(\A_{n\times n}\)</span>, denoted <span class="math inline">\(Tr(\A)\)</span> or <span class="math inline">\(Trace(\A)\)</span>, is the sum of the diagonal elements of <span class="math inline">\(\A\)</span>,
<span class="math display">\[Tr(\A)=\sum_{i=1}^n A_{ii}.\]</span></li>
</ul>
</div>
<div id="exercises" class="section level2" number="1.8">
<h2><span class="header-section-number">1.8</span> Exercises</h2>
<ol>
<li>
<p>Use the following matrices or vectors to answer the following questions:
<span class="math display">\[\begin{equation*}
\mathbf{A}=\left(\begin{array}{ccc} 1&amp;3&amp;8\\3&amp;0&amp;-2\\4&amp;1&amp;-3 \end{array}\right) \quad \mathbf{M}=\left(\begin{array}{cccc} 1&amp;8&amp;-2&amp;5\\2&amp;8&amp;1&amp;7 \end{array}\right) \quad 
\mathbf{D} = \left(\begin{array}{ccc} 1&amp;0&amp;0\\0&amp;5&amp;0\\0&amp;0&amp;3\end{array}\right) 
\end{equation*}\]</span>
<span class="math display">\[\begin{equation*}
\mathbf{X}=\left(\begin{array}{cc} 780 &amp; 95000\\600 &amp; 60000\\550 &amp; 65000\\400 &amp; 35000\\450 &amp; 40000\\750 &amp;80000\end{array}\right) \quad
\mathbf{t} = \left(\begin{array}{c} 1\\1.3\\0.8\\2\\2.5\\0.8\\0.9 \end{array}\right) \quad 
\mathbf{v}=\left(\begin{array}{c} 6\\3\\-1\\2\end{array}\right) \quad \mathbf{u}=\left(\begin{array}{cccc} 6&amp;4&amp;8&amp;1\end{array}\right)
\end{equation*}\]</span></p>
<ol style="list-style-type:lower-alpha">
<li>
Write the appropriate size/dimensions next to each matrix:
<ol style="list-style-type:lower-roman">
<li>
<span class="math inline">\(\mathbf{A}\)</span><br />

<li>
<span class="math inline">\(\mathbf{M}\)</span><br />

<li>
<span class="math inline">\(\mathbf{D}\)</span>
<li>
<span class="math inline">\(\mathbf{X}\)</span><br />

<li>
<span class="math inline">\(\mathbf{t}\)</span><br />

<li>
<span class="math inline">\(\mathbf{v}\)</span><br />

<li>
<span class="math inline">\(\mathbf{u}\)</span><br />

</ol>
<li>
<p>Which of these matrices are square? Which are rectangular?</p>
<li>
Give the following quantities:
<ol style="list-style-type:lower-roman">
<li>
<span class="math inline">\(A_{12}=\)</span><br />

<li>
<span class="math inline">\(M_{21}=\)</span><br />

<li>
<span class="math inline">\(\D_{\star3}=\)</span><br />

<li>
<span class="math inline">\(\mathbf{M}_{2\star}=\)</span><br />

<li>
<span class="math inline">\(X_{42}=\)</span><br />

<li>
<span class="math inline">\(t_5=\)</span><br />

<li>
<span class="math inline">\(v_3=\)</span><br />

</ol>
<li>
What are the diagonal elements of <span class="math inline">\(\A\)</span>?
</ol>
<li>
For each of the following matrices and vectors, give their dimension. Label each as a matrix or vector. For each matrix, indicate whether the matrix is square or rectangular.
<ol style="list-style-type:lower-alpha">
<li>
<span class="math display">\[\A=\left(\begin{matrix} 2 &amp; 3 &amp; -1\\1&amp;-1&amp;1\\2&amp;2&amp;1 \end{matrix}\right)\]</span><br />

<li>
<span class="math display">\[\mathbf{h}=\left(\begin{matrix} -1\\-4\\1\\2 \end{matrix}\right)\]</span><br />

<li>
<span class="math display">\[\B=\left(\begin{matrix}   B_{11}&amp;B_{12}&amp;B_{13}\\B_{21}&amp;B_{22}&amp;B_{23}\\B_{31}&amp;B_{32}&amp;B_{33}\\B_{41}&amp;B_{42}&amp;B_{43}\end{matrix}\right)\]</span><br />

<li>
<span class="math display">\[\C=\left(\begin{matrix} 1 &amp; 0.3 &amp; -0.9 &amp; 0.1\\0.3 &amp; 1 &amp; 0.8 &amp; -0.5\\-0.9&amp;0.8&amp;1&amp;-0.6\\0.1&amp;-0.5&amp;-0.6&amp;1 \end{matrix}\right)\]</span><br />

<li>
<span class="math display">\[\A = [A_{ij}] \quad \mbox{where } i=1,2,3 \quad \mbox{and   } j=1,2\]</span><br />

</ol>
<li>
For the following quantities, use what you know about notation to tell if they are matrices, vectors, or scalars:
<ol style="list-style-type:lower-alpha">
<li>
<span class="math inline">\(\mathbf{H}\)</span><br />

<li>
<span class="math inline">\(\mathbf{W}\)</span><br />

<li>
<span class="math inline">\(n\)</span><br />

<li>
<span class="math inline">\(\v_2\)</span><br />

<li>
<span class="math inline">\(v_2\)</span><br />

<li>
<span class="math inline">\(\mathbf{M}_{\star 2}\)</span><br />

<li>
<span class="math inline">\(\lambda\)</span><br />

<li>
<span class="math inline">\(A_{ij}\)</span><br />

<li>
<span class="math inline">\(\mathbf{r}\)</span><br />

</ol>
<li>
<p>The matrix <span class="math inline">\(\C\)</span> from exercise 2d is the correlation matrix discussed earlier in this chapter. What is the trace of <span class="math inline">\(\C\)</span>? For any correlation matrix computed using <span class="math inline">\(p\)</span> variables, what should we expect the trace to be?</p>
<li>
<p>If <span class="math display">\[\v^T = \left(\begin{matrix} 1&amp;6&amp;-1&amp;\sqrt{2} \end{matrix}\right),\]</span> then what is <span class="math inline">\(\v\)</span>?</p>
<li>
For each of the following, write the vector or matrix that is specified:
<ol style="list-style-type:lower-alpha">
<li>
<span class="math inline">\(\e_3 \in \Re^4\)</span>
<li>
<span class="math inline">\(\D=diag\{2, \sqrt{3}, -1\}\)</span>
<li>
<span class="math inline">\(\e \in \Re^3\)</span>
<li>
<span class="math inline">\(\I_2\)</span>
</ol>
<li>
<p>How do you know if a matrix is symmetric? Give an example of a symmetric matrix.</p>
<li>
<p>Give an example of a <span class="math inline">\(4\times 4\)</span> upper triangular matrix and a <span class="math inline">\(3\times 3\)</span> lower triangular matrix.</p>
<li>
Suppose we measure the heights of 10 people, <span class="math inline">\(person_1, person_2, \dots, person_{10}\)</span>.
<ol style="list-style-type:lower-alpha">
<li>
If we define a matrix <span class="math inline">\(\S\)</span> as
<span class="math display">\[S_{ij} = height(person_i) - height(person_j)\]</span>
is the matrix <span class="math inline">\(\S\)</span> symmetric? What is the trace(<span class="math inline">\(\S\)</span>)?<br />

<li>
If instead we create a matrix <span class="math inline">\(\mathbf{G}\)</span> where
<span class="math display">\[G_{ij} = [height(person_i) - height(person_j)]^2\]</span>
is the matrix <span class="math inline">\(\mathbf{G}\)</span> symmetric? What is the trace(<span class="math inline">\(\mathbf{G}\)</span>)?<br />

</ol>
<li>
<p>Refer to the network/graph shown below. This particular network has 6 numbered vertices (the circles) and edges which connect the vertices. Each edge has a certain {weight} (perhaps reflecting some level of association between the vertices) which is given as a number.</p>
<li>
Use the network shown below to answer the following questions.<br />

<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-8"></span>
<img src="figs/graphex.jpg" alt="Graph (Network) for exercise 11" width="60%" />
<p class="caption">
Figure 1.3: Graph (Network) for exercise 11
</p>
</div>
<ol style="list-style-type:lower-alpha">
<li>
Write down the adjacency matrix, <span class="math inline">\(\A\)</span>, for this graph where <span class="math inline">\(\A_{ij}\)</span> reflects the weight of the edge connecting vertex <span class="math inline">\(i\)</span> and vertex <span class="math inline">\(j\)</span>.<br />

<li>
The <strong>degree</strong> of a vertex is defined as the sum of the weights of the edges connected to that vertex. Create a vector <span class="math inline">\(\mathbf{d}\)</span> such that <span class="math inline">\(d_i\)</span> is the degree of node <span class="math inline">\(i\)</span>.<br />

</ol>
<!-- ## List of Key Terms  -->
<!-- - linear -->
<!-- - matrix -->
<!-- - vector -->
<!-- - scalar -->
<!-- - $A_{ij}$ -->
<!-- - $\A_{\star j}$ -->
<!-- - $\A_{i \star}$ -->
<!-- - dimensions -->
<!-- - diagonal element -->
<!-- - square matrix -->
<!-- - rectangular matrix -->
<!-- - network -->
<!-- - graph -->
<!-- - adjacency matrix -->
<!-- - correlation matrix -->
<!-- - transpose -->
<!-- - symmetric matrix -->
<!-- - trace -->
<!-- - diagonal matrix -->
<!-- - identity matrix -->
<!-- - upper triangular matrix -->
<!-- - lower triangular matrix -->

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="mult.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/shainarace/LinearAlgebra/edit/master/00-introLA.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": "https://github.com/shainarace/LinearAlgebra/blob/master/00-introLA.Rmd",
"text": null
},
"download": null,
"toc": {
"collapse": "section",
"scroll_highlight": true
},
"search": {
"engine": "lunr"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
